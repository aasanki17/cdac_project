<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>What’s new in the OpenShift 4.3 console developer experience</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3wCRqyvpZrQ/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="OpenShift 4.3" scheme="searchisko:content:tags" /><category term="OpenShift Developer Perspective" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Steve Speicher</name></author><id>searchisko:content:id:jbossorg_blog-what_s_new_in_the_openshift_4_3_console_developer_experience</id><updated>2020-01-15T14:57:13Z</updated><published>2020-01-15T14:57:13Z</published><content type="html">&lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674517 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete2.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete2.png" alt="" width="512" height="289" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete2.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete2-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;p&gt;The developer experience is significantly improved in the &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; 4.3 web console. If you have used the Developer perspective, which was introduced in OpenShift 4.2 Console, you are probably familiar with our streamlined user flows for deploying applications, the new Topology view, and the enhanced experience around &lt;a href="https://developers.redhat.com/blog/2020/01/08/the-new-tekton-pipelines-extension-for-visual-studio-code/"&gt;OpenShift Pipelines powered by Tekton&lt;/a&gt; and OpenShift Serverless powered by Knative. This release continues to improve upon the features that were introduced in 4.2 and introduces new flows and features for the developer.&lt;/p&gt; &lt;h2&gt;Deploying applications&lt;/h2&gt; &lt;p&gt;The Developer perspective offers several built-in ways to streamline the process of deploying applications, services, and databases. In 4.3, you’ll find the following improvements to these user flows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Support for the deployment of an image stream from an internal registry.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674417 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-1024x476.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream.png" alt="" width="1600" height="743" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-300x139.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-768x357.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-1024x476.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Builder image detection in the Import from Git user flow.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674437 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git.png" alt="" width="512" height="258" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git-300x151.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Deployment options between Kubernetes Deployments (default), OpenShift DeploymentConfigs, and Knative service (tech preview). (This option gives the developer easy ways to switch between deployment types without having to learn YAML or other templating solutions.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment.png" alt="" width="512" height="289" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;p&gt;For more details on these improvements, check out the &lt;i&gt;xxxx blog&lt;/i&gt; by Parvathy.&lt;/p&gt; &lt;h2&gt;Topology view&lt;/h2&gt; &lt;p&gt;The Topology view offers significant usability improvements and new flows for 4.3:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Switch between a graphical and list presentation of your project.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674457 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-1024x577.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology.png" alt="" width="1600" height="902" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-768x433.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-1024x577.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-1024x575.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2.png" alt="" width="1600" height="898" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-300x168.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-768x431.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-1024x575.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Access the ability to scale up/down and increase/decrease your pod count easily via the side panel or the associated detail page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674477 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-1024x580.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling.png" alt="" width="1600" height="906" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-300x170.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-768x435.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-1024x580.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;View real-time visualization of rolling and recreate rollouts on the component in Topology, as well as in the associated side panel.&lt;/li&gt; &lt;li&gt;Delete an application, which is accomplished by deleting all components with the associated label, as defined by the Kubernetes-recommended labels.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674507 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1.png" alt="" width="548" height="310" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1-300x169.png 300w" sizes="(max-width: 548px) 100vw, 548px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Access context menus are via right-click as well as in the Actions menu in the associated side panel.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2.png" alt="" width="512" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;Miscellaneous&lt;/h2&gt; &lt;p&gt;Additional improvements let you:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Click the newly added Project details navigation item to access a new Project dashboard and delete your Project.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674537 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-1024x575.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project.png" alt="" width="1600" height="899" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-768x432.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-1024x575.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Share your projects easily with other users through a simplified view of Project membership if you are a developer with the appropriate access.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674547 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-membership.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-membership.png" alt="" width="565" height="311" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Troubleshoot problems with your applications by running Prometheus Query Language (PromQL) queries on your Project and examining the metrics visualized on a plot. This Tech Preview feature is available on the Metrics page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674557 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot.png" alt="" width="512" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;h2&gt;Binding&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://github.com/operator-backing-service-samples/postgresql-operator" target="_blank" rel="noopener noreferrer"&gt;Service Binding Operator&lt;/a&gt; enables application developers to more easily bind applications together with Operator-managed backing services such as databases, without having to manually configure secrets, ConfigMaps, etc. In Topology in 4.3, you can quickly and easily create a binding between two components.&lt;/p&gt; &lt;h3&gt;OpenShift Pipelines&lt;/h3&gt; &lt;p&gt;The OpenShift Pipeline Operator enhances the OpenShift console with developer CI/CD solutions that leverage the Tekton project. In 4.3, you’ll see the following improvements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Users can enable CI/build Pipelines to an application.&lt;/li&gt; &lt;li&gt;When a pipeline is associated with a component in Topology, the user will be able to view the association as well as preview the Pipeline&amp;#8217;s status in the Topology view.&lt;/li&gt; &lt;li&gt;The Logs tab of a Pipeline run provides the ability to view the task logs in real time. Users now have the ability to download a Pipeline&amp;#8217;s task logs.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674567 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs.png" alt="" width="512" height="289" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;h2&gt;Red Hat OpenShift Serverless&lt;/h2&gt; &lt;p&gt;In 4.3, improvements to the Tech Preview for &lt;a href="https://www.openshift.com/learn/topics/serverless" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift Serverless&lt;/a&gt; features include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Visualizing Knative Services as a group, which allows the user to review all revisions in the traffic block visually in the Topology view.&lt;/li&gt; &lt;li&gt;Letting users modify the traffic distribution among the revisions of a Knative service.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674577 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless.png" alt="" width="512" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Showing elements from Knative Eventing, namely event sources, which provides developers with quick insight into which event sources will trigger their application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter size-full wp-image-674587 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources.png" alt="" width="377" height="227" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources.png 377w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources-300x181.png 300w" sizes="(max-width: 377px) 100vw, 377px" /&gt;&lt;/p&gt; &lt;h2&gt;Learn more&lt;/h2&gt; &lt;p&gt;Interested in learning more about application development with OpenShift? Check out these Red Hat resources for &lt;a href="http://developers.redhat.com/openshift"&gt;application development on OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Provide feedback&lt;/h2&gt; &lt;p&gt;Join our &lt;a href="https://groups.google.com/forum/#!forum/openshift-dev-users" target="_blank" rel="noopener noreferrer"&gt;OpenShift Developer Experience Google Group&lt;/a&gt;, participate in discussions, or attend our Office Hours Feedback session. Or, drop us an &lt;a href="mailto:openshift-ux@redhat.com" target="_blank" rel="noopener noreferrer"&gt;email&lt;/a&gt; with your comments about the OpenShift Console user experience.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#038;title=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" data-a2a-url="https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/" data-a2a-title="What’s new in the OpenShift 4.3 console developer experience"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/"&gt;What’s new in the OpenShift 4.3 console developer experience&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3wCRqyvpZrQ" height="1" width="1" alt=""/&gt;</content><summary>The developer experience is significantly improved in the Red Hat OpenShift 4.3 web console. If you have used the Developer perspective, which was introduced in OpenShift 4.2 Console, you are probably familiar with our streamlined user flows for deploying applications, the new Topology view, and the enhanced experience around OpenShift Pipelines powered by Tekton and OpenShift Serverless powered b...</summary><dc:creator>Steve Speicher</dc:creator><dc:date>2020-01-15T14:57:13Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/</feedburner:origLink></entry><entry><title>JBossWS 5.4.0.FInal is released !</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZIz8N39hz7w/jbossws-540final-is-released.html" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_jbossws" scheme="searchisko:content:tags" /><author><name>jimma</name></author><id>searchisko:content:id:jbossorg_blog-jbossws_5_4_0_final_is_released</id><updated>2020-01-15T09:41:51Z</updated><published>2020-01-15T09:41:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br class="Apple-interchange-newline" /&gt;I am pleased to annouce JBossWS 5.4.0 Final is out. In this release we upgraded many components as usual and brings Elytron client configuration support. Apache CXF is now upgraded to 3.3.4 and more issues has been fixed in this release. For more detailed info and full list of issues resolved, please check&amp;nbsp;&lt;a href="https://issues.redhat.com/secure/ReleaseNote.jspa?version=12341950&amp;amp;projectId=12310050"&gt;release notes.&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;If you have any problem and want to send feedback for this new release, please post at&lt;a href="https://developer.jboss.org/en/jbossws/cxf"&gt;&amp;nbsp;jbossws forum&lt;/a&gt;&amp;nbsp;or file issues in JIRA at:&amp;nbsp;&lt;a href="https://issues.jboss.org/projects/JBWS"&gt;https://issues.jboss.org/projects/JBWS&lt;/a&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZIz8N39hz7w" height="1" width="1" alt=""/&gt;</content><summary>I am pleased to annouce JBossWS 5.4.0 Final is out. In this release we upgraded many components as usual and brings Elytron client configuration support. Apache CXF is now upgraded to 3.3.4 and more issues has been fixed in this release. For more detailed info and full list of issues resolved, please check release notes. If you have any problem and want to send feedback for this new release, pleas...</summary><dc:creator>jimma</dc:creator><dc:date>2020-01-15T09:41:00Z</dc:date><feedburner:origLink>http://jbossws.blogspot.com/2020/01/jbossws-540final-is-released.html</feedburner:origLink></entry><entry><title>Installing debugging tools into a Red Hat OpenShift container with oc-inject</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VuD5C7RO2W0/" /><category term="CodeReady Containers" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="debugging" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Serhei Makarov</name></author><id>searchisko:content:id:jbossorg_blog-installing_debugging_tools_into_a_red_hat_openshift_container_with_oc_inject</id><updated>2020-01-15T08:00:05Z</updated><published>2020-01-15T08:00:05Z</published><content type="html">&lt;p&gt;A previous article, &lt;a href="https://developers.redhat.com/blog/2019/12/17/debugging-applications-within-red-hat-openshift-containers"&gt;Debugging applications within Red Hat OpenShift containers,&lt;/a&gt; gives an overview of tools for debugging applications within &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; containers, and existing restrictions on their use. One of the restrictions discussed in that article was an inability to install debugging tool packages into an ordinary, unprivileged container once it was already instantiated. In such a container, debugging tool packages have to be included when the container image is built, because once the container is instantiated, using package installation commands requires elevated privileges that are not available to the ordinary container user.&lt;/p&gt; &lt;p&gt;However, there are important situations where it is desirable to install a debugging tool into an already-instantiated container. In particular, if the resolution of a problem requires access to the temporary state of a long-running containerized application, the usual method of adding debugging tools to the container by rebuilding the container image and restarting the application will destroy that temporary state.&lt;/p&gt; &lt;p&gt;To provide a way to add debugging tools to unprivileged containers, I developed a utility, called &lt;code&gt;oc-inject&lt;/code&gt;, that can temporarily copy a debugging tool into a container. Instead of relying on package management or other privileged operations, &lt;code&gt;oc-inject&lt;/code&gt;’s implementation is based on the existing and well-supported OpenShift operations &lt;code&gt;oc rsync&lt;/code&gt; and &lt;code&gt;oc exec&lt;/code&gt;, which do not require any elevated privileges.&lt;/p&gt; &lt;p&gt;This article describes the current capabilities of the &lt;code&gt;oc-inject&lt;/code&gt; utility, which is available &lt;a href="https://github.com/serhei/oc-inject/" target="_blank" rel="noopener noreferrer"&gt;on GitHub&lt;/a&gt; or &lt;a href="https://copr.fedorainfracloud.org/coprs/serhei/oc-inject/" target="_blank" rel="noopener noreferrer"&gt;via a Fedora COPR repository&lt;/a&gt;. The &lt;code&gt;oc-inject&lt;/code&gt; utility works on any Linux system that includes Python 3, the &lt;code&gt;ldd&lt;/code&gt; utility, and the Red Hat OpenShift command-line tool &lt;code&gt;oc&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-663407"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="how-oc-inject-works"&gt;How &lt;code&gt;oc-inject&lt;/code&gt; works&lt;/h2&gt; &lt;p&gt;&lt;code&gt;oc-inject&lt;/code&gt; is a command-line utility that can be invoked from any local Linux system that has been configured to communicate with an OpenShift cluster via the &lt;code&gt;oc&lt;/code&gt; command-line tool. The &lt;code&gt;oc-inject&lt;/code&gt; utility has the following command-line syntax:&lt;/p&gt; &lt;pre&gt;oc-inject &amp;#60;pod_ID&amp;#62; &amp;#60;executable&amp;#62; &lt;/pre&gt; &lt;p&gt;Here, &lt;code&gt;pod_ID&lt;/code&gt; is the name of an OpenShift container, and &lt;code&gt;executable&lt;/code&gt; is the name of an executable on the local system.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;oc-inject&lt;/code&gt; utility installs the specified executable into the container and then runs it. An executable installed by &lt;code&gt;oc-inject&lt;/code&gt; could be a debugging tool or another system utility that would otherwise not be available in the container.&lt;/p&gt; &lt;p&gt;For example, using &lt;code&gt;oc-inject&lt;/code&gt;, we can install and run the &lt;code&gt;htop&lt;/code&gt; utility in order to visualize the CPU and memory usage of processes within the container &lt;code&gt;myapp-rxxrw&lt;/code&gt;(outlined in Figure 1):&lt;/p&gt; &lt;pre&gt;$ oc-inject -it myapp-rxxrw htop &lt;/pre&gt; &lt;div id="attachment_663417" style="width: 547px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-663417" class="wp-image-663417 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/oc-inject-for-blog-final.png" alt="Diagram of oc-inject operation." width="537" height="329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/oc-inject-for-blog-final.png 537w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/oc-inject-for-blog-final-300x184.png 300w" sizes="(max-width: 537px) 100vw, 537px" /&gt;&lt;p id="caption-attachment-663417" class="wp-caption-text"&gt;Figure 1: The flow of an &lt;code&gt;oc-inject&lt;/code&gt; operation.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;oc-inject&lt;/code&gt; utility operates as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;First, &lt;code&gt;oc-inject&lt;/code&gt; uses the &lt;a href="http://man7.org/linux/man-pages/man1/ldd.1.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;ldd&lt;/code&gt;&lt;/a&gt; utility to identify the set of shared libraries required by the executable.&lt;/li&gt; &lt;li&gt;Second, &lt;code&gt;oc-inject&lt;/code&gt; invokes the OpenShift &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-copying-files.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;oc rsync&lt;/code&gt;&lt;/a&gt; command to copy the executable and the identified shared libraries into a temporary directory within the container.&lt;/li&gt; &lt;li&gt;Finally, &lt;code&gt;oc-inject&lt;/code&gt; invokes the &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-remote-commands.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;oc exec&lt;/code&gt;&lt;/a&gt; command to run the executable. In order for the executable to use the shared libraries within the temporary directory, &lt;code&gt;oc-inject&lt;/code&gt; sets the executable’s &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; environment variable to this directory.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It is important to keep in mind that if the executable installed by &lt;code&gt;oc-inject&lt;/code&gt; depends on files other than shared libraries, &lt;code&gt;oc-inject&lt;/code&gt; will not copy these files into the container. This limitation narrows the set of executables that can be installed with &lt;code&gt;oc-inject&lt;/code&gt;. However, in practice, such commonly used debugging tools as &lt;code&gt;gdbserver&lt;/code&gt; and &lt;code&gt;strace&lt;/code&gt; require only shared libraries and can be successfully installed and run using &lt;code&gt;oc-inject&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The examples in the following sections illustrate how the &lt;code&gt;gdbserver&lt;/code&gt; and &lt;code&gt;strace&lt;/code&gt; debugging tools can be installed and used to observe the behavior of a containerized application. The procedures in these examples were tested on an OpenShift 4.2.8 cluster managed with &lt;a href="https://github.com/code-ready/crc" target="_blank" rel="noopener noreferrer"&gt;CodeReady Containers 1.2.0&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="first-example-tracing-system-calls-in-a-postgresql-process-using-strace"&gt;Example 1: Tracing system calls in a PostgreSQL process using &lt;code&gt;strace&lt;/code&gt;&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;Create an OpenShift application based on the &lt;a href="https://github.com/sclorg/rails-ex" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;rails-ex&lt;/code&gt;&lt;/a&gt; application template from the &lt;a href="https://www.softwarecollections.org/" target="_blank" rel="noopener noreferrer"&gt;software-collections.org&lt;/a&gt; repository:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ git clone https://github.com/sclorg/rails-ex $ oc new-app rails-ex/openshift/templates/rails-postgresql.json -p SOURCE_REPOSITORY_URL=https://github.com/sclorg/rails-ex &lt;/pre&gt; &lt;p&gt;This template creates several containers, including a container with a PostgreSQL database.&lt;/p&gt; &lt;ol start="2"&gt; &lt;li&gt;Run &lt;code&gt;oc get pods&lt;/code&gt; and &lt;code&gt;ps -ax&lt;/code&gt;to identify the name of the PostgreSQL container and the PIDs of processes within the container:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc get pods NAME READY STATUS RESTARTS AGE postgresql-1-deploy 0/1 Completed 0 4m23s postgresql-1-jfg52 1/1 Running 0 4m8s rails-postgresql-example-1-build 0/1 Completed 0 4m24s rails-postgresql-example-1-deploy 0/1 Completed 0 72s rails-postgresql-example-1-gg5hm 1/1 Running 0 26s rails-postgresql-example-1-hook-pre 0/1 Completed 0 63s $ oc exec -it postgresql-1-jfg52 -- ps -ax PID TTY STAT TIME COMMAND 1 ? Ss 0:00 postgres 62 ? Ss 0:00 postgres: logger process 64 ? Ss 0:00 postgres: checkpointer process 65 ? Ss 0:00 postgres: writer process 66 ? Ss 0:00 postgres: wal writer process 67 ? Ss 0:00 postgres: autovacuum launcher process 68 ? Ss 0:00 postgres: stats collector process 69 ? Ss 0:00 postgres: bgworker: logical replication launcher 391 ? Ss 0:00 postgres: userY5Q root 10.128.0.190(39754) idle 414 ? Ss 0:00 postgres: userY5Q root 10.128.0.190(39882) idle 481 pts/0 Rs+ 0:00 ps -ax &lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;We are interested in tracing the system calls made by one of the PostgreSQL worker processes. The output of &lt;code&gt;ps -ax&lt;/code&gt; lists two such processes, with PIDs 391 and 414. For this example, we will trace the process with PID 414. We invoke &lt;code&gt;oc-inject&lt;/code&gt; to install an &lt;code&gt;strace&lt;/code&gt; executable into the container:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc-inject -it postgresql-1-jfg52 -- strace -p 414 /tmp/oc-inject-af154698/strace: Process 414 attached epoll_wait(3, [{EPOLLIN, {u32=34512144, u64=34512144}}], 1, -1) = 1 recvfrom(11, "Q\0\0\0\rSELECT 1\0", 8192, 0, NULL, NULL) = 14 sendto(10, "\2\0\0\0\230\0\0\0\1@\0\0\1\0\0\0\2\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 152, 0, NULL, 0) = 152 sendto(11, "T\0\0\0!\0\1?column?\0\0\0\0\0\0\0\0\0\0\27\0\4\377\377\377\377"..., 66, 0, NULL, 0) = 66 recvfrom(11, "P\0\0\0+\0SELECT \"articles\".* FROM \""..., 8192, 0, NULL, NULL) = 81 lseek(15, 0, SEEK_END) = 8192 lseek(16, 0, SEEK_END) = 16384 lseek(15, 0, SEEK_END) = 8192 sendto(11, "1\0\0\0\0042\0\0\0\4T\0\0\0\204\0\5id\0\0\0@\24\0\1\0\0\0\27\0\4"..., 268, 0, NULL, 0) = 268 recvfrom(11, 0xcad700, 8192, 0, NULL, NULL) = -1 EAGAIN (Resource temporarily unavailable) epoll_wait(3, [{EPOLLIN, {u32=34512144, u64=34512144}}], 1, -1) = 1 ... ^C /tmp/oc-inject-af154698/strace: Process 414 detached &amp;#60;detached ...&amp;#62; command terminated with exit code 130 &lt;/pre&gt; &lt;p&gt;Thus, we obtained a trace of interactions between the PostgreSQL process and the underlying operating system.&lt;/p&gt; &lt;h2 id="second-example-tracing-postgresql-internal-behaviour-by-attaching-to-sdt-markers-with-gdbserver"&gt;Example 2: Tracing PostgreSQL&amp;#8217;s internal behavior by attaching to SDT markers with &lt;code&gt;gdbserver&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;In this example, we demonstrate how to collect trace data from a PostgreSQL process. In order to do this, we use statically defined tracing (SDT) markers, which identify various high-level events within the process. The SDT marker for an event has a list of arguments that provide information about the event to a debugging tool.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; Many applications, libraries, and runtimes provide built-in SDT markers that can be traced by GDB, including the PostgreSQL, MySQL and MariaDB database engines; core system libraries such as &lt;code&gt;glibc&lt;/code&gt;; and language runtimes for Python, Ruby, Java, and Node.js. A more comprehensive list of applications and libraries with SDT markers is maintained on the &lt;a href="https://sourceware.org/systemtap/wiki/" target="_blank" rel="noopener noreferrer"&gt;SystemTap wiki&lt;/a&gt;. In addition to the &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Static-Probe-Points.html" target="_blank" rel="noopener noreferrer"&gt;official GDB documentation&lt;/a&gt;, an earlier &lt;a href="https://blog.sergiodj.net/2012/03/29/gdb-and-systemtap-probes-part-1.html" target="_blank" rel="noopener noreferrer"&gt;blog series&lt;/a&gt; by Sergio Durigan Junior (&lt;a href="https://blog.sergiodj.net/2012/10/27/gdb-and-systemtap-probes-part-2.html" target="_blank" rel="noopener noreferrer"&gt;part 2&lt;/a&gt;, &lt;a href="https://blog.sergiodj.net/2012/11/02/gdb-and-systemtap-probes-part-3.html" target="_blank" rel="noopener noreferrer"&gt;part 3&lt;/a&gt;) gives more information about GDB’s support for tracing SDT markers.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;PostgreSQL’s built-in SDT markers identify various high-level database events. The PostgreSQL documentation gives &lt;a href="https://www.postgresql.org/docs/10/dynamic-trace.html" target="_blank" rel="noopener noreferrer"&gt;a full description of available markers&lt;/a&gt; and associated arguments.&lt;/p&gt; &lt;p&gt;The following steps illustrate how to collect SDT trace data using &lt;code&gt;gdbserver&lt;/code&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Start a containerized PostgreSQL process following the same procedure as described in Example 1&amp;#8217;s first step.&lt;/li&gt; &lt;li&gt;Start a GDB session outside the container:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ gdb GNU gdb (GDB) Fedora 8.2-6.fc29 Copyright (C) 2018 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &amp;#60;http://gnu.org/licenses/gpl.html&amp;#62; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type "show copying" and "show warranty" for details. (gdb) &lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Invoke &lt;code&gt;oc-inject&lt;/code&gt; to install and run &lt;code&gt;gdbserver&lt;/code&gt; within the container, and instruct the GDB session to connect to the &lt;code&gt;gdbserver&lt;/code&gt;’s standard input and output:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) target extended-remote | oc-inject -i postgresql-1-jfg52 -- gdbserver --multi - Remote debugging using | oc-inject -i postgresql-1-jfg52 -- gdbserver --multi - Remote debugging using stdio (gdb) &lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Instruct the running &lt;code&gt;gdbserver&lt;/code&gt; to attach to the desired PostgreSQL worker process (PID 391 in this case):&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) attach 391 Attaching to process 391 Attached; pid = 391 Reading /opt/rh/rh-postgresql10/root/usr/bin/postgres from remote target... warning: File transfers from remote targets can be slow. Use "set sysroot" to access files locally instead. Reading /opt/rh/rh-postgresql10/root/usr/bin/postgres from remote target... Reading symbols from target:/opt/rh/rh-postgresql10/root/usr/bin/postgres...Reading /opt/rh/rh-postgresql10/root/usr/bin/postgres.debug from remote target... Reading /opt/rh/rh-postgresql10/root/usr/bin/.debug/postgres.debug from remote target... Missing separate debuginfo for target:/opt/rh/rh-postgresql10/root/usr/bin/postgres Try: dnf --enablerepo='*debug*' install /usr/lib/debug/.build-id/14/1c5e620c9ea33d7e9214b6e4d5a4d4519e4a10.debug Reading symbols from .gnu_debugdata for target:/opt/rh/rh-postgresql10/root/usr/bin/postgres...(no debugging symbols found)...done. (no debugging symbols found)...done. ... 0x00007fee94155973 in __select_nocancel () from target:/lib64/libc.so.6 &lt;/pre&gt; &lt;ol start="5"&gt; &lt;li&gt;After attaching to the process, obtain a list of available SDT markers with GDB’s &lt;code&gt;info probes&lt;/code&gt; command:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) info probes ... stap postgresql query__rewrite__start 0x00000000007189fd 0x0000000000cac470 target:/opt/rh/rh-postgresql10/root/usr/bin/postgres stap postgresql query__start 0x0000000000718c45 0x0000000000cac464 target:/opt/rh/rh-postgresql10/root/usr/bin/postgres stap postgresql smgr__md__read__done 0x00000000007142c5 0x0000000000cac42a target:/opt/rh/rh-postgresql10/root/usr/bin/postgres ... &lt;/pre&gt; &lt;ol start="6"&gt; &lt;li&gt;Define a tracepoint that will trigger on the &lt;code&gt;query__start&lt;/code&gt; marker, which identifies the event of the process starting to execute a database query:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) trace -probe-stap query__start Tracepoint 1 at 0x718c45 &lt;/pre&gt; &lt;p&gt;As described in the &lt;a href="https://www.postgresql.org/docs/10/dynamic-trace.html" target="_blank" rel="noopener noreferrer"&gt;PostgreSQL documentation&lt;/a&gt;, the &lt;code&gt;query__start&lt;/code&gt; marker returns the query string through an argument of type &lt;code&gt;char *&lt;/code&gt;. In a GDB session, this argument can be referenced via the identifier &lt;code&gt;$_probe_arg0&lt;/code&gt;.&lt;/p&gt; &lt;ol start="7"&gt; &lt;li&gt;Define the actions we want GDB to take whenever the tracepoint triggers. Let’s say that we want GDB to collect the value of the &lt;code&gt;query__start&lt;/code&gt; SDT marker&amp;#8217;s query string argument. To do so, we must instruct GDB to collect both the value of the argument as well as the memory locations this value points to:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) actions 1 &amp;#62;collect $_probe_arg0 &amp;#62;collect *(unsigned char *)$_probe_arg0@512 &amp;#62;end &lt;/pre&gt; &lt;ol start="8"&gt; &lt;li&gt;Use the &lt;code&gt;tstart&lt;/code&gt; command described in GDB’s documentation on &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Tracepoints.html#Tracepoints" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;tracepoints&lt;/code&gt;&lt;/a&gt; to collect trace data while the program continues running:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) tstart (gdb) continue &amp;#38; &lt;/pre&gt; &lt;ol start="9"&gt; &lt;li&gt;As the program continues to run, GDB will continue to collect trace data. To view the collected data, interrupt the program and use the &lt;code&gt;tfind&lt;/code&gt; command to step through the collected trace data:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) interrupt (gdb) tstatus Trace is running on the target. Collected 18 trace frames. Trace buffer has 5229992 bytes of 5242880 bytes free (0% full). Trace will stop if GDB disconnects. Not looking at any trace frame. Trace started at 7393.098048 secs, stopped -111.-534238 secs later. (gdb) tstop (gdb) tfind start Found trace frame 0, tracepoint 1 #0 0x0000000000718c45 in exec_simple_query () (gdb) print/x $_probe_arg0 $1 = 0x1763358 (gdb) tdump Data collected at tracepoint 1, trace frame 0: $_probe_arg0 = 24523608 *(unsigned char *)$_probe_arg0@512 = "SELECT 1\000\000\000ticles\".* FROM \"articles\"\000\000\000\000CT indrelid, indkey, generate_subscripts(indkey, 1) idx\n", ' ' &amp;#60;repeats 11 times&amp;#62;, "FROM pg_index\n WHERE indrelid = '\"articles\"'::regclass\n", ' ' &amp;#60;repeats 12 times&amp;#62;, "AND indisprimary\n"... (gdb) while ($trace_frame != -1) &amp;#62;tfind &amp;#62;tdump &amp;#62;end ... Found trace frame 10, tracepoint 1 Data collected at tracepoint 1, trace frame 10: $_probe_arg0 = 24523608 *(unsigned char *)$_probe_arg0@512 = "BEGIN\000\000\000\000\000\000\002\000\000\000\001\062\000\000\000\001\061\000\001\000\000\000 SELECT indrelid, indkey, generate_subscripts(indkey, 1) idx\n", ' ' &amp;#60;repeats 11 times&amp;#62;, "FROM pg_index\n WHERE indrelid = '\"comments\"'::regclass\n", ' ' &amp;#60;repeats 12 times&amp;#62;, "AND indisprimary\n"... Found trace frame 11, tracepoint 2 Data collected at tracepoint 2, trace frame 11: Found trace frame 12, tracepoint 1 Data collected at tracepoint 1, trace frame 12: $_probe_arg0 = 24523608 *(unsigned char *)$_probe_arg0@512 = "COMMIT\000\000\000\000\000\000\000\000\000\005\000\000\000\021This is a comment\000\000\000\vRead me!\000\000\000\001\062\000\000\000\032\062\060\061\071-11-27 19:49:34.771435\000\000\000\032\062\060\061\071-11-27 19:49:34.771435\000\001\000\000\000ING \"id\"\000\000\005", '\000' &amp;#60;repeats 21 times&amp;#62;, "ents\"'::regclass\n", ' ' &amp;#60;repeats 12 times&amp;#62;, "AND indisprimary\n"... &lt;/pre&gt; &lt;p&gt;Thus, we used SDT markers to extract information about an event in the PostgreSQL process. After we finish observing this PostgreSQL process, use GDB’s &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Connecting.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;monitor exit&lt;/code&gt;&lt;/a&gt; command to stop the &lt;code&gt;gdbserver&lt;/code&gt; process within the container:&lt;/p&gt; &lt;pre&gt;(gdb) detach (gdb) monitor exit (gdb) ^D &lt;/pre&gt; &lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The examples in this article illustrate how the current version of &lt;code&gt;oc-inject&lt;/code&gt; increases the options available for debugging containerized applications.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#038;title=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" data-a2a-url="https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/" data-a2a-title="Installing debugging tools into a Red Hat OpenShift container with oc-inject"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/"&gt;Installing debugging tools into a Red Hat OpenShift container with oc-inject&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VuD5C7RO2W0" height="1" width="1" alt=""/&gt;</content><summary>A previous article, Debugging applications within Red Hat OpenShift containers, gives an overview of tools for debugging applications within Red Hat OpenShift containers, and existing restrictions on their use. One of the restrictions discussed in that article was an inability to install debugging tool packages into an ordinary, unprivileged container once it was already instantiated. In such a co...</summary><dc:creator>Serhei Makarov</dc:creator><dc:date>2020-01-15T08:00:05Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/</feedburner:origLink></entry><entry><title>How to use the VS Code Tekton Pipelines extension</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/O61FCdWpO9Y/" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Tekton" scheme="searchisko:content:tags" /><author><name>Lindsey Tulloch</name></author><id>searchisko:content:id:jbossorg_blog-how_to_use_the_vs_code_tekton_pipelines_extension</id><updated>2020-01-14T14:39:17Z</updated><published>2020-01-14T14:39:17Z</published><content type="html">&lt;p&gt;&lt;a href="https://tekton.dev/"&gt;The Tekton Project&lt;/a&gt;, which was announced in March after branching off from the &lt;a href="https://knative.dev/"&gt;Knative project&lt;/a&gt;, is creating excitement as a &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes-&lt;/a&gt;native CI/CD pipeline tool.&lt;/p&gt; &lt;p&gt;Tekton offers the flexibility and agnosticism that Kubernetes is celebrated for and is positioned to become the first open standardized engine for &lt;a href="https://developers.redhat.com/blog/2019/07/19/getting-started-with-tekton-on-red-hat-openshift/"&gt;executing pipelines&lt;/a&gt;. Although the project is still in the early stages of development, we couldn’t wait to start making it easier for developers to jump on the Tekton train. In this article, we&amp;#8217;ll take a quick look at the Tekton Pipelines extension and how to use it.&lt;/p&gt; &lt;p&gt;&lt;span id="more-626797"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The initial release of the &lt;a href="https://github.com/redhat-developer/vscode-tekton"&gt;Visual Studio (VS) Code Tekton Pipelines extension&lt;/a&gt; by Red Hat was developed over the course of a summer internship by &lt;a href="https://github.com/onyiny-ang"&gt;Lindsey Tulloch &lt;/a&gt;with support from developers of the &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-openshift-connector"&gt;OpenShift Connector extension&lt;/a&gt;, &lt;a href="https://github.com/dgolovin"&gt;Denis Golovin&lt;/a&gt; and &lt;a href="https://github.com/mohitsuman"&gt;Mohit Suman &lt;/a&gt;and the Red Hat Pipelines team—in particular, &lt;a href="https://github.com/vdemeester"&gt;Vincent Demeester&lt;/a&gt; and &lt;a href="https://github.com/sthaha"&gt;Sunil Thaha. &lt;/a&gt;&lt;/p&gt; &lt;p&gt;The Tekton Pipelines extension offers all of the same functionality as the Tekton CLI tool as well as a pipeline view. This not only allows developers to visualize pipeline deployments they&amp;#8217;re developing but also allows for intuitive interaction with pipeline resources.&lt;/p&gt; &lt;p&gt;Today, the Tekton Pipelines extension is available on &lt;a href="https://marketplace.visualstudio.com/vscode"&gt;VSCode Marketplace&lt;/a&gt; and works with the latest version of VSCode.&lt;/p&gt; &lt;p&gt;&lt;b&gt;Supported Features:&lt;/b&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Snippets for Pipeline Resources&lt;/li&gt; &lt;li&gt;Pipeline View&lt;/li&gt; &lt;li&gt;CLI functionality implemented via clicking on the desired pipeline resource&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Using the Tekton Pipelines extension&lt;/h2&gt; &lt;p&gt;Installing the Tekton Pipelines extension will trigger the installation of both the Kubernetes extension and the latest release of the Tekton CLI tool &lt;code&gt;tkn&lt;/code&gt;.  Once these are installed, you will see a “Tekton Pipelines” view in your VSCode explorer with &lt;code&gt;Pipelines&lt;/code&gt;, &lt;code&gt;Tasks&lt;/code&gt;, &lt;code&gt;ClusterTasks&lt;/code&gt;, and &lt;code&gt;PipelineResource&lt;/code&gt; as top-level tree nodes. Clicking on any of these nodes expands the view to display nested resources.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;Pipelines&lt;/code&gt; shows: &lt;code&gt;Pipelines &amp;#62; PipelineRuns &amp;#62; TaskRuns&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Tasks&lt;/code&gt; shows: &lt;code&gt;Tasks &amp;#62; TaskRuns&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;ClusterTasks&lt;/code&gt; shows: &lt;code&gt;ClusterTasks&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PipelineResources&lt;/code&gt; shows: &lt;code&gt;PipelineResources&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Clicking on any of these resources displays a range of actions, matching the functionality of the &lt;code&gt;tkn&lt;/code&gt; CLI tool.&lt;/p&gt; &lt;h4&gt;Actions available for a Tekton Pipeline/Task/ClusterTask&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;Pipeline -&amp;#62; Start&lt;/code&gt; — Start a Pipeline with user-selected resources, parameters and service account.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Pipeline -&amp;#62; Restart&lt;/code&gt; — Restart the last PipelineRun.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Pipeline/Task/ClusterTask -&amp;#62; List&lt;/code&gt; — List all Pipelines in a Cluster.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Pipeline -&amp;#62; Describe&lt;/code&gt; — Print the JSON of a selected Pipeline.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Pipeline/Task/ClusterTask -&amp;#62; Delete&lt;/code&gt; — Delete the selected Pipeline.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Actions available for a Tekton PipelineRun&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;PipelineRun/TaskRun -&amp;#62; List&lt;/code&gt; — List all PipelineRuns/TaskRuns in a Pipeline/Task.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PipelineRun/TaskRun -&amp;#62; Describe&lt;/code&gt; — Describe the selected PipelineRun/TaskRun.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PipelineRun/TaskRun -&amp;#62; Logs&lt;/code&gt; — Print Logs from the selected PipelineRun/TaskRun.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PipelineRun/TaskRun -&amp;#62; Delete&lt;/code&gt; — Delete the selected PipelineRun/TaskRun.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PipelineRun -&amp;#62; Cancel&lt;/code&gt; — Cancel the selected PipelineRun.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Tekton Project is still in the early stages of development, so there is plenty of space for expansion and improvement within the extension. Of course, suggestions and pull requests are always welcome on the GitHub repo, found &lt;a href="https://github.com/redhat-developers/vscode-tekton"&gt;here.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#38;linkname=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fhow-to-use-the-vs-code-tekton-pipelines-extension%2F&amp;#038;title=How%20to%20use%20the%20VS%20Code%20Tekton%20Pipelines%20extension" data-a2a-url="https://developers.redhat.com/blog/2020/01/14/how-to-use-the-vs-code-tekton-pipelines-extension/" data-a2a-title="How to use the VS Code Tekton Pipelines extension"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/14/how-to-use-the-vs-code-tekton-pipelines-extension/"&gt;How to use the VS Code Tekton Pipelines extension&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/O61FCdWpO9Y" height="1" width="1" alt=""/&gt;</content><summary>The Tekton Project, which was announced in March after branching off from the Knative project, is creating excitement as a Kubernetes-native CI/CD pipeline tool. Tekton offers the flexibility and agnosticism that Kubernetes is celebrated for and is positioned to become the first open standardized engine for executing pipelines. Although the project is still in the early stages of development, we c...</summary><dc:creator>Lindsey Tulloch</dc:creator><dc:date>2020-01-14T14:39:17Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/14/how-to-use-the-vs-code-tekton-pipelines-extension/</feedburner:origLink></entry><entry><title>Introducing new Red Hat Enterprise Linux certification for software partner products</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/hTxIJ7Z5m7A/" /><category term="Announcement" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Red Hat Certification" scheme="searchisko:content:tags" /><category term="red hat ecosystem" scheme="searchisko:content:tags" /><category term="Red Hat Enterprise Linux" scheme="searchisko:content:tags" /><category term="Red Hat Partner" scheme="searchisko:content:tags" /><category term="RHEL8" scheme="searchisko:content:tags" /><author><name>Joel Destefano</name></author><id>searchisko:content:id:jbossorg_blog-introducing_new_red_hat_enterprise_linux_certification_for_software_partner_products</id><updated>2020-01-14T08:00:56Z</updated><published>2020-01-14T08:00:56Z</published><content type="html">&lt;p&gt;We are pleased to announce an improved software certification for Red Hat partner products built for &lt;a href="https://developers.redhat.com/rhel8/"&gt;Red Hat Enterprise Linux 8 (RHEL 8)&lt;/a&gt;. This new RHEL software certification validates the use of common best practices, improves joint supportability, and promotes your product in the new &lt;a href="https://catalog.redhat.com" target="_blank" rel="noopener noreferrer"&gt;Red Hat Ecosystem Catalog&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;What is this certification?&lt;/h2&gt; &lt;p&gt;This certification now features a partner executable test suite that produces results that are then reviewed by Red Hat. Your non-containerized software is certified when the test results show successful interoperability with Red Hat Enterprise Linux 8 in a secure, supportable manner using best practices. Once verified, you can promote your product(s) in the Red Hat Ecosystem catalog.&lt;/p&gt; &lt;p&gt;In addition, Red Hat will grant partners a complimentary Limited membership to &lt;a href="https://redhatconnect.connect.tsanet.org/#/" target="_blank" rel="noopener noreferrer"&gt;TSANet&lt;/a&gt; for collaborative customer case management to improve their ongoing user experiences.&lt;span id="more-664567"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Why Red Hat Enterprise Linux 8?&lt;/h2&gt; &lt;p&gt;Red Hat Enterprise Linux, the industry leader for enterprise Linux deployments, is the foundation of Red Hat’s open hybrid cloud portfolio, providing the underlying engine that allows complex workloads to be developed and deployed across physical, virtual, private, and public cloud environments with greater confidence and control. After just a few months, Red Hat Enterprise Linux 8 is already the number one RHEL version among developers with hundreds of thousands of downloads.&lt;/p&gt; &lt;p&gt;To learn more about RHEL 8, visit the &lt;a href="https://developers.redhat.com/rhel8/"&gt;RHEL 8 Developer page&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Certification features &lt;/b&gt;&lt;/h2&gt; &lt;p&gt;This new Red Hat Enterprise Linux software certification means that:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Your executable is verified with a Red Hat seal of approval.&lt;/li&gt; &lt;li&gt;Your products are differentiated as more supportable, interoperable, and secure.&lt;/li&gt; &lt;li&gt;You get a Limited membership to TSANet (compliments of Red Hat) to improve supportability and your customers’ long term experiences.&lt;/li&gt; &lt;li&gt;You get complimentary technical assistance for certification&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Partner benefits&lt;/h2&gt; &lt;p&gt;The benefits partners receive from this certification include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;That your certified software is published and promoted in the new &lt;a href="http://catalog.redhat.com" target="_blank" rel="noopener noreferrer"&gt;Red Hat Ecosystem catalog&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;A co-branded product brief.&lt;/li&gt; &lt;li&gt;Exposure to the Red Hat sales force.&lt;/li&gt; &lt;li&gt;The opportunity to participate in Red Hat Partner Connect podcasts.&lt;/li&gt; &lt;li&gt;Social media awareness.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Customer benefits&lt;/h2&gt; &lt;p&gt;The benefits customers receive from this certification are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A greater degree of operability assurances when using Red Hat-certified products.&lt;/li&gt; &lt;li&gt;Mitigated security risks through verified best practices.&lt;/li&gt; &lt;li&gt;Improved supportability from Red Hat and Red Hat partners via TSANet.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;&lt;b&gt;Learn more&lt;/b&gt;&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://rhc4tp-cms-prod-vpc-76857813.s3.amazonaws.com/s3fs-public/RH-RHEL8-Cert-Datasheet-US.pdf" target="_blank" rel="noopener noreferrer"&gt;Red Hat Enterprise Linux Software Certification datasheet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_software_suite/1.0/html/red_hat_enterprise_linux_software_certification_policy_guide/index" target="_blank" rel="noopener noreferrer"&gt;Red Hat Enterprise Linux Software Certification policy&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://redhat-connect.gitbook.io/partner-guide-for-red-hat-enterprise-linux-zone/" target="_blank" rel="noopener noreferrer"&gt;Red Hat Enterprise Linux Software Certification workflow guide&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://connect.redhat.com/" target="_blank" rel="noopener noreferrer"&gt;Red Hat Partner Connect portal&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://catalog.redhat.com/?extIdCarryOver=true&amp;#38;intcmp=701f2000000RQykAAG&amp;#38;sc_cid=701f2000000Rm25AAC" target="_blank" rel="noopener noreferrer"&gt;Red Hat Ecosystem Catalog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Also, read more about &lt;a href="https://redhatconnect.connect.tsanet.org/#/" target="_blank" rel="noopener noreferrer"&gt;TSANet.org here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Red Hat certification and other services for software partners&lt;/h2&gt; &lt;p&gt;If you work for a software partner (e.g. ISV, etc.), learn about Red Hat Partner Connect &lt;a href="https://developers.redhat.com/techpartner/"&gt;certification and other services&lt;/a&gt; for you and your company.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#38;linkname=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F14%2Fintroducing-new-red-hat-enterprise-linux-certification-for-software-partner-products%2F&amp;#038;title=Introducing%20new%20Red%20Hat%20Enterprise%20Linux%20certification%20for%20software%20partner%20products" data-a2a-url="https://developers.redhat.com/blog/2020/01/14/introducing-new-red-hat-enterprise-linux-certification-for-software-partner-products/" data-a2a-title="Introducing new Red Hat Enterprise Linux certification for software partner products"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/14/introducing-new-red-hat-enterprise-linux-certification-for-software-partner-products/"&gt;Introducing new Red Hat Enterprise Linux certification for software partner products&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/hTxIJ7Z5m7A" height="1" width="1" alt=""/&gt;</content><summary>We are pleased to announce an improved software certification for Red Hat partner products built for Red Hat Enterprise Linux 8 (RHEL 8). This new RHEL software certification validates the use of common best practices, improves joint supportability, and promotes your product in the new Red Hat Ecosystem Catalog. What is this certification? This certification now features a partner executable test ...</summary><dc:creator>Joel Destefano</dc:creator><dc:date>2020-01-14T08:00:56Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/14/introducing-new-red-hat-enterprise-linux-certification-for-software-partner-products/</feedburner:origLink></entry><entry><title>How to Install Red Hat Process Automation Manager 7.5 in Minutes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/c2u5cEP1wZM/how-to-install-red-hat-process-automation-manager-75-in-minutes.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_red_hat_process_automation_manager_7_5_in_minutes</id><updated>2020-01-14T10:04:13Z</updated><published>2020-01-13T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&amp;nbsp;&lt;a href="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s1600/rhpam-login.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-original-height="927" data-original-width="1600" height="185" src="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s320/rhpam-login.png" title="" width="320" /&gt;&lt;/a&gt;While you've seen the many &lt;a href="http://www.schabell.org/search/label/OpenShift" target="_blank"&gt;developer tooling articles&lt;/a&gt; where I've helped you to &lt;a href="https://gitlab.com/redhatdemocentral" target="_blank"&gt;get started on the OpenShift Container Platform&lt;/a&gt;, there is still a basic need to run our tooling locally on our own machine.&lt;br /&gt;&lt;br /&gt;With that in mind, here's an update that installs the latest process automation tooling for your development projects in just minutes on your very own machine.&lt;br /&gt;&lt;br /&gt;Not only that, it's done in just three easy steps and done in a few minutes!&lt;br /&gt;&lt;br /&gt;See if I'm telling the truth, let's install it now:&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;Just three easy steps to a fully installed and configured Red Hat Process Automation manager.&lt;br /&gt;&lt;h2 data-sourcepos="6:1-8:122" dir="auto"&gt;Install on your machine&lt;/h2&gt;&lt;a href="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s1600/rhpam-business-central.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-original-height="935" data-original-width="1600" height="186" src="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s320/rhpam-business-central.png" title="" width="320" /&gt;&lt;/a&gt;There are a few component you'll need to download for free from the provided developers site, then obtain the project linked below, add the downloads, and run the installation script.&lt;br /&gt;&lt;br /&gt;Watch the installation unfold before your eyes, with configuration, settings, and user creation all detailed in the script output so you can learn from the installation.&lt;br /&gt;&amp;nbsp;&lt;/div&gt;&lt;div&gt;Give it a try with these three steps: &lt;br /&gt;&lt;ol data-sourcepos="8:1-17:0" style="text-align: left;"&gt;&lt;li data-sourcepos="8:1-9:0"&gt;&lt;div data-sourcepos="8:4-8:122"&gt;&lt;a href="https://gitlab.com/bpmworkshop/rhpam-install-demo/-/archive/master/rhpam-install-demo-master.zip"&gt;Download and unzip.&lt;/a&gt;&lt;/div&gt;&lt;div data-sourcepos="8:4-8:122"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="10:1-11:0"&gt;&lt;div data-sourcepos="10:4-10:81"&gt;Add products to installs directory, see installs/README for details and links.&lt;/div&gt;&lt;div data-sourcepos="10:4-10:81"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="14:1-15:0"&gt;&lt;div data-sourcepos="12:4-12:92"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges.&lt;/div&gt;&lt;div data-sourcepos="12:4-12:92"&gt;&lt;br /&gt;&lt;/div&gt;&amp;nbsp;Login to &lt;a href="http://localhost:8080/business-central" rel="nofollow noreferrer noopener" target="_blank"&gt;http://localhost:8080/business-central&lt;/a&gt; (u:erics / p:redhatpam1!)&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;That's it, not it's time to enjoy your installed and configured Red Hat Process Automation Manager.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;Not sure how to get started with process automation? Try one of these &lt;a href="https://bpmworkshop.gitlab.io/index-redhat.html#/3" rel=" noreferrer noopener" target="_blank"&gt;online workshops&lt;/a&gt; to build a first project from scratch.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=FN4CYGpgrAM:s8OCeO4c6_E:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=FN4CYGpgrAM:s8OCeO4c6_E:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=FN4CYGpgrAM:s8OCeO4c6_E:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=FN4CYGpgrAM:s8OCeO4c6_E:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=FN4CYGpgrAM:s8OCeO4c6_E:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/FN4CYGpgrAM" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/c2u5cEP1wZM" height="1" width="1" alt=""/&gt;</content><summary> While you've seen the many developer tooling articles where I've helped you to get started on the OpenShift Container Platform, there is still a basic need to run our tooling locally on our own machine. With that in mind, here's an update that installs the latest process automation tooling for your development projects in just minutes on your very own machine. Not only that, it's done in just thr...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-01-13T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/FN4CYGpgrAM/how-to-install-red-hat-process-automation-manager-75-in-minutes.html</feedburner:origLink></entry><entry><title>Architecting messaging solutions with Apache ActiveMQ Artemis</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/x7Aid60qMeM/" /><category term="artemis" scheme="searchisko:content:tags" /><category term="event-driven" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="messaging" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="middleware" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat Integration" scheme="searchisko:content:tags" /><author><name>Bilgin Ibryam</name></author><id>searchisko:content:id:jbossorg_blog-architecting_messaging_solutions_with_apache_activemq_artemis</id><updated>2020-01-10T08:12:59Z</updated><published>2020-01-10T08:12:59Z</published><content type="html">&lt;p&gt;As an architect in the Red Hat Consulting team, I’ve helped countless customers with their &lt;a href="https://www.redhat.com/en/products/integration" target="_blank" rel="noopener noreferrer"&gt;integration&lt;/a&gt; challenges over the last six years. Recently, I had a few consulting gigs around &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;Red Hat AMQ 7&lt;/a&gt; Broker (the enterprise version of &lt;a href="https://activemq.apache.org/components/artemis/" target="_blank" rel="noopener noreferrer"&gt;Apache ActiveMQ Artemis&lt;/a&gt;), where the requirements and outcomes were similar. That similarity made me think that the whole requirement identification process and can be more structured and repeatable.&lt;/p&gt; &lt;p&gt;This guide is intended for sharing what I learned from these few gigs in an attempt to make the AMQ Broker architecting process, the resulting deployment topologies, and the expected effort more predictable—at least for the common use cases. As such, what follows will be useful for messaging and integration consultants and architects tasked with creating a messaging architecture for Apache Artemis, and other messaging solutions in general. This article focuses on Apache Artemis. It doesn’t cover Apache Kafka, &lt;a href="https://strimzi.io/" target="_blank" rel="noopener noreferrer"&gt;Strimzi&lt;/a&gt;, Apache Qpid, EnMasse, or the EAP messaging system, which are all components of our &lt;a href="https://developers.redhat.com/products/amq/overview" target="_blank" rel="noopener noreferrer"&gt;Red Hat AMQ 7&lt;/a&gt; product offering.&lt;span id="more-665337"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Typical customer requirements&lt;/h2&gt; &lt;p&gt;In my experience, a typical middleware use case has fairly basic messaging requirements and constraints that fall under a few general categories. Based on the findings in these areas, there are a few permutations of the possible solutions with pros and cons, and the final resulting architectures are fairly common. Designing, documenting, communicating the constraints and implementing these common architectures, should be well understood by messaging SMEs. Anything different from these standard architectures should be expected to require additional effort and lead to a bespoke architecture with unique non-functional and operational characteristics.&lt;/p&gt; &lt;p&gt;This article covers the following hypothetical but common messaging scenario. Here is a customer describing the typical messaging requirements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We have around 100 microservices with Spring Boot and Apache Camel that use messaging extensively.&lt;/li&gt; &lt;li&gt;All of our services are scalable and high availability (HA), and we expect the messaging layer to have similar characteristics.&lt;/li&gt; &lt;li&gt;We use mostly point-to-point but we also have a few publish-subscribe interactions.&lt;/li&gt; &lt;li&gt;Most of our messages are small in the KB range, but there are those that are fairly large in the single-digit MBs range.&lt;/li&gt; &lt;li&gt;We don’t know our current message throughput, it changes as we add new services using messaging.&lt;/li&gt; &lt;li&gt;We don’t use any exotic features, but we have use cases with message selectors, scheduled delivery, and TTL.&lt;/li&gt; &lt;li&gt;We need to preserve the message ordering with and without message grouping.&lt;/li&gt; &lt;li&gt;We primarily use JMS from our Java-based services and AMQP from the few .NET services.&lt;/li&gt; &lt;li&gt;We don’t like XA, but in a handful of services, we use distributed transactions involving the message broker.&lt;/li&gt; &lt;li&gt;We can replay messages if necessary, but we cannot lose any message, and we use only persistent messages.&lt;/li&gt; &lt;li&gt;We put all failed messages in DLQs and discard later.&lt;/li&gt; &lt;li&gt;We want to know all of the best practices and naming conventions.&lt;/li&gt; &lt;li&gt;All broker-to-broker communication and client-to-broker communication must be secured.&lt;/li&gt; &lt;li&gt;We want to control who can create queues, read and write messages, and browse.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you hear these above requirements, you are in familiar territory, and this article should be useful to you. If not, and there are specific hardware, throughput, topological, or other requirements, clone the Apache Artemis &lt;a href="https://github.com/apache/activemq-artemis" target="_blank" rel="noopener noreferrer"&gt;repo&lt;/a&gt; and go deeper. And don’t forget to share what you learn with others later.&lt;/p&gt; &lt;h2&gt;The constraints identification approach&lt;/h2&gt; &lt;p&gt;In addition to the obvious customer requirements and wishes, other hard and soft constraints will shape the resulting architecture. The customer might or might not be aware of these constraints and dependencies, and it is your job to dig deep and discover them all.&lt;/p&gt; &lt;p&gt;The approach I follow is to start from the fundamental and hard to change requirements, such as infrastructure and storage, as shown in Figure 1. Explore what options there are for each and document the constraints with pros and cons. Then, do the same for the orchestration layer, if present.&lt;/p&gt; &lt;p&gt;The fundamental constraints will then dictate what is possible in the upper layers, such as options for high availability and scalability. Further up in the layers the flexibility increases, and one can choose swap load balancers and different client implementations without impacting the layers below.&lt;/p&gt; &lt;div id="attachment_665357" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df168dd09c78.png" target="_blank" rel="noopener noreferrer"&gt;&lt;img aria-describedby="caption-attachment-665357" class="wp-image-665357 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df168dd09c78-1024x782.png" alt="Breaking down higher level requirements into specific constraints" width="640" height="489" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df168dd09c78-1024x782.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df168dd09c78-300x229.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df168dd09c78-768x587.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-665357" class="wp-caption-text"&gt;Figure 1: Breaking down higher-level requirements into specific constraints.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Finding the answers to these points and identifying what is most important and where the customer is willing to make a compromise will help you identify a workable architecture. Next, let’s go deeper, and see what the specific constraints are for an Apache Artemis-based solution.&lt;/p&gt; &lt;h2&gt;Infrastructure&lt;/h2&gt; &lt;p&gt;This an area where the customer will have the least amount of flexibility, and your goal is to identify how the message broker fits within the available infrastructure in a reliable configuration. It is unlikely that a customer will change their infrastructure provider for their messaging needs, so try to identify a fit-for-purpose solution.&lt;/p&gt; &lt;p&gt;Typically, common messaging infrastructures are based on on-premise infrastructure with virtualizers, NFS storage, and F5 load balancers. This infrastructure all can be within a single data center or spread across two data centers (rather than three, unfortunately). In an alternative scenario, the customer might be using AWS (or equivalent), such as EC2, EBS, EFS, RDS, or ELBs. Typically, all of these options spread across three AZs in a single region. That is the most common AWS setup for a small-to-midsize integration use case.&lt;/p&gt; &lt;p&gt;Apart from computing, storage, and load balancers, at this stage, we want to identify the data center&amp;#8217;s topology, network latency, and throughput. Is the client using a single datacenter, two data centers, or any other odd number? Is it an active-active, or active-passive data center topology?&lt;/p&gt; &lt;p&gt;Last but not least, what are the operating system, JDK, and client stacks? This information is easily verifiable from the AMQ 7-supported &lt;a href="https://access.redhat.com/articles/2791941" target="_blank" rel="noopener noreferrer"&gt;configuration&lt;/a&gt; page, including what is tested, what is supported, for how long, and whatnot.&lt;/p&gt; &lt;p&gt;While on-premise and cloud-based infrastructures offer similar resources, the difference typically is in the number of data centers and the operation, failover, and disaster recovery models. Influencing these fundamental models is a slow process, which is why we want to identify these constraints first.&lt;/p&gt; &lt;h2&gt;Storage&lt;/h2&gt; &lt;p&gt;Once we have identified the broader infrastructure level details, the next step is to focus on storage. Storage is a part of the infrastructure layer but it requires separate considerations here. When HA is a requirement (which is always the case), storage is the most critical and limiting factor for the messaging architecture. Pay special attention to what options the customer&amp;#8217;s infrastructure offers, as the answer will significantly limit the possible deployment topologies.&lt;/p&gt; &lt;h3&gt;Storage capacity&lt;/h3&gt; &lt;p&gt;Capacity is hardly a real issue, as typically there are many unknowns when estimating the exact storage capacity required. Most customers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use the message broker as their temporary staging area, where messages are consumed as fast as the consumers can handle. Typically there are no consumer service RPOs defined, and it is not clear for how long messages can keep accumulating.&lt;/li&gt; &lt;li&gt;Put messages into DLQs, but will not have a clear idea of what to do with these messages later. Replaying failed messages is dependent on the actual business requirements and is not always desirable.&lt;/li&gt; &lt;li&gt;Expect that if a message is 1MB in size, it will consume 1MB on the disk. As you all know from experience by now, that is not the case. The same message could end up consuming multiple times more storage, depending on the type of messaging interaction style, caching, and other configurations.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;All of these and other scenarios can lead to the accumulation of messages in the broker and consume hundreds of gigabytes of storage. If the customer has no answers to these points, the only proven approach for estimating the required storage size is &amp;#8220;finger in the air.&amp;#8221; Luckily, Artemis—like its predecessors—has &lt;a href="https://activemq.apache.org/components/artemis/documentation/latest/flow-control.html" target="_blank" rel="noopener noreferrer"&gt;flow control&lt;/a&gt;, which can protect the broker from running out of storage. This question typically comes down to whether to throw an exception or block the producers to protect the broker.&lt;/p&gt; &lt;h3&gt;Storage type&lt;/h3&gt; &lt;p&gt;Storage type is much more important and dictates what high-availability options will be required later. For example, if the broker is on Kubernetes, there is no master/slave, and therefore, there is no need for a shared file system with a distributed lock such as NFSv4, GFS2, or GlusterFS. But, the file system should ensure that the journal has high availability.&lt;/p&gt; &lt;p&gt;When the broker is on VMs (not on Kubernetes), the simpler option to implement and operate is to use a supported shared file system. Notice that AWS EFS service is not a full NFSv4 spec, but it is still supported as a shared storage option for Artemis. If a shared file system is not present, alternatively, you can use a relational database as storage with a potential performance hit. Check which relational databases are supported (currently, that is Oracle, DB2, MSSQL). Note that using AWS RDS is a viable option here too.&lt;/p&gt; &lt;p&gt;If no shared file system or relational database is possible, you can consider replication. Replication requires additional considerations. One big advantage of replication is that the messaging and middleware team will not depend on any storage team to provision the infrastructure. Also, there won’t be a cost for shared filesystems or relational databases, and the broker performs its data replication. There are customers who like this aspect, but all good things come at a cost, such as the fact that a reliable replication requires a minimum of three master and three slave brokers to avoid split-brain situations.&lt;/p&gt; &lt;p&gt;There is also the option of using &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.4/html/configuring_amq_broker/setting-up-broker-cluster-configuring#configuring-high-availability-configuring" target="_blank" rel="noopener noreferrer"&gt;the network pinger&lt;/a&gt;, which is risky and not recommended in practice. The network pinger avoids the need for three of everything, but you should only use the network pinger if you are unable to use three or more live backup groups. If you are using the replication high availability policy, and if you have only a single live backup pair, configuring network pinging reduces (but does not remove) the chances of encountering network isolation.&lt;/p&gt; &lt;p&gt;Another cost is that split-brain could happen, not only for network partitions and server crashes, but also as a consequence of overload, CPU starvation, long I/O waits, long garbage collection pauses, and other reasons. Also, replication can happen only within a single datacenter and LAN and requires a reliable, low-latency network. AWS AZs in the same region are considered different data centers, as Amazon does not commit to networking latency SLAs either. Finally, replication also has a performance hit compared to a shared store option.&lt;/p&gt; &lt;p&gt;Ultimately, the critical point about storage is that while we can make the broker process and the client process HA, the datastore itself also has to be HA and durable, and this is possible only through data replication. As part of AMQ architecture, it is important to identify who is replicating the data (the file system, the database, or the message broker itself through replication) to ensure that the data is highly available.&lt;/p&gt; &lt;h2&gt;Orchestration&lt;/h2&gt; &lt;p&gt;Here, the question boils down to checking whether the customer will run the message broker on container orchestrators such as Kubernetes and &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;, on bare VMs through homegrown bash scripts, or Red Hat Ansible &lt;a href="https://github.com/redhat-cop/ansible-middleware-playbooks" target="_blank" rel="noopener noreferrer"&gt;playbooks&lt;/a&gt;. If the customer is not targeting OpenShift, the questions in this section can be skipped. If the messaging infrastructure will run on containers and be orchestrated by Kubernetes, there are a few constraints and architectural implications to consider.&lt;/p&gt; &lt;p&gt;For example, there is no master/slave failover (so no hot backup broker present). Instead, there is a single pod per broker instance that is health monitored and restarted by Kubernetes, which ensures broker HA. The single pod failover process with Kubernetes is different from master/slave with replication failover on-premise. Because there is no master/slave failover, there is no need for message replication between master/slave either. There is also no need for distributed file locking, which means that there is no need for a shared file system with distributed locking capabilities and that one can still use these file systems to mount the same storage to different Kubernetes nodes and pods, but the locking capability of the file system is not a prerequisite any longer.&lt;/p&gt; &lt;p&gt;For example, in the case of a node failure, Kubernetes would start a broker pod on a different node and make the same PV and data available. Because there is no master/slave, there is no need for ReadWriteMany, but only for ReadWriteOnce volume types. That said, you might still need a shared file system that can be mounted to different nodes in the case of node failure (such as AWS EBS, which can be mounted to different EC2 instances in the same region).&lt;/p&gt; &lt;p&gt;So, are there messaging clients located outside of the cluster? Connecting to the broker from within an OpenShift cluster is straightforward through Kubernetes services, but there are restrictions for connecting to the broker from outside of the Kubernetes cluster.&lt;/p&gt; &lt;p&gt;Next, can external clients use a protocol that supports SNI? The easiest option is typically to use SSL and access the broker from the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.3/html-single/deploying_amq_broker_on_openshift_container_platform/index#creating-route-ocp_broker-ocp" target="_blank" rel="noopener noreferrer"&gt;router&lt;/a&gt;. If using TLS for clients is not possible, consider using NodePort &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.3/html-single/deploying_amq_broker_on_openshift_container_platform/index#basic_client_cluster_port_binding" target="_blank" rel="noopener noreferrer"&gt;binding&lt;/a&gt; which requires cluster-admin permissions.&lt;/p&gt; &lt;p&gt;Finally, there is a &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html-single/deploying_amq_broker_on_openshift_container_platform/index#journal-recovery-broker-ocp" target="_blank" rel="noopener noreferrer"&gt;scaledown controller&lt;/a&gt; to drain and migrate messages when scaling down broker pods in a cluster.&lt;/p&gt; &lt;p&gt;There might be a few other differences, but failover, discovery, and scaledown is automated, and the broker fundamentals do not change on Kubernetes and Openshift.&lt;/p&gt; &lt;h2&gt;High availability&lt;/h2&gt; &lt;p&gt;When a customer talks about &amp;#8220;high availability,&amp;#8221; what they mean is a full-stack, highly-available messaging layer. That means HA storage, HA brokers, HA clients, HA load balancers, and HA anything else that might be in between. To cover this scenario, you have to consider the availability of every component in the stack, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_665367" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df16f78bf119.png"&gt;&lt;img aria-describedby="caption-attachment-665367" class="wp-image-665367 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df16f78bf119-1024x951.png" alt="Redundancy at every layer." width="640" height="594" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df16f78bf119-1024x951.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df16f78bf119-300x279.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df16f78bf119-768x713.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df16f78bf119.png 1092w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-665367" class="wp-caption-text"&gt;Figure 2: Redundancy at every layer.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Storage&lt;/h3&gt; &lt;p&gt;The only way to ensure HA for data is by replicating the data. You have to identify who replicates the data and where the data is replicated: locally, across VMs, across DCs, and so on. Most customers will want to survive a single data center outage without a message loss, which requires a cross data center replication mechanism. The easiest option is to delegate the journal replication to the file system. This option has implications on cost and dependency on infrastructure teams. For example, if you replicate data using a database, consider the cost and performance hit. If you replicate data using Artemis journal replication but consider the customer&amp;#8217;s maturity to operate a broker cluster, consider split-brain scenarios, data center latencies, and performance hits.&lt;/p&gt; &lt;h3&gt;Broker&lt;/h3&gt; &lt;p&gt;On Kubernetes, broker HA is achieved through health checks and container restarts. On-premise, the broker HA is achieved through master/slave (shared store or replication). When replication is used, the slave will already hold the queues in memory, and therefore is pretty much ready to go in case of failover. With shared storage, when the slave gets hold of the lock, then the queues need to be read from the journals ahead of the slave takeover. The time for a shared storage slave to take over will be dependent on the number and size of messages in the journal.&lt;/p&gt; &lt;p&gt;When we talk about broker HA, it comes down to an active-passive failover mechanism (with Kubernetes being an exception). But Artemis also has an active-active clustering mechanism used primarily for scalability rather than HA. In active-active clustering, every message belongs to only one broker, and losing an active broker will make its messages also unaccessible—but a positive side effect of that issue is that the broker infrastructure is still up and functioning. Clients can use active instances and exchange messages with the drawback of temporarily not accessing the messages that are in the failed broker. To sum up, active-active clustering is primarily for scalability, but it also partially improves the availability with temporary message unavailability.&lt;/p&gt; &lt;h3&gt;Load balancer&lt;/h3&gt; &lt;p&gt;If there is a load balancer, prefer one that is already HA in the organization, such as F5s. If Qpid is used, you will need two or more active instances for high availability.&lt;/p&gt; &lt;h3&gt;Clients&lt;/h3&gt; &lt;p&gt;This is probably the easiest part, as most customers will already run the client services in redundantly HA fashion, which means two or more instances of consumers and producers most of the time. A side effect of running multiple consumers is that message ordering is not guaranteed. This is where message groups and exclusive consumers can be used.&lt;/p&gt; &lt;h2&gt;Scalability&lt;/h2&gt; &lt;p&gt;Scalability is relatively easier to achieve with Artemis. Primarily, there are two approaches to scaling the message broker.&lt;/p&gt; &lt;h3&gt;Active-active clustering&lt;/h3&gt; &lt;p&gt;Create a single logical broker cluster that is scaled transparently from the clients. This can be three masters and three slaves (replication or shared storage doesn’t matter) to start with, which means that clients can use any of the masters to produce and consume the messages. The broker will perform load balancing and message distributions. Such a messaging infrastructure is scalable and supports many queues and topics with different messaging patterns. Artemis can handle large and small messages effectively, so there is no need for using separate broker clusters depending on the message size either.&lt;/p&gt; &lt;p&gt;A few of the consequences of active-active clustering are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Message ordering is not preserved.&lt;/li&gt; &lt;li&gt;Message grouping needs to be clustered.&lt;/li&gt; &lt;li&gt;Scaling down requires message draining.&lt;/li&gt; &lt;li&gt;Browsing the brokers and the queues is not centralized.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Client-side partitioning&lt;/h3&gt; &lt;p&gt;Create separate, smaller master/slave clusters for different purposes. You can have a separate master/slave cluster for real-time, batch, small messages, large messages, per business domain, criticality, team, etc. When a broker pair reaches its capacity limit, create a separate broker pair and reconfigure clients to use it.&lt;/p&gt; &lt;p&gt;This technique works as long as the clients can choose which cluster to connect to (hence the name client-side partitioning). There is also a use case here for &lt;a href="https://qpid.apache.org/" target="_blank" rel="noopener noreferrer"&gt;Apache Qpid&lt;/a&gt; where you can add new brokers and assign addresses to them without the clients needing to know anything about the location of these brokers, and therefore, simplifying the clients and making the messaging network dynamic.&lt;/p&gt; &lt;h3&gt;Load balancer&lt;/h3&gt; &lt;p&gt;While a load balancer is not a mandatory component of the messaging stack, it is an architectural decision whether you are going to use client-side load balancing or an external load balancer. With an external load balancer, you have the fact that customers like using their existing load balancers such as F5 for messaging, too. Plus, load balancers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Already exist in many organizations, they are already HA, and they support many protocols—so it makes sense to use them for messaging too.&lt;/li&gt; &lt;li&gt;Allow a single IP for all clients.&lt;/li&gt; &lt;li&gt;Can do health checks and failover to the master broker (that is, a probe attempting to connect to the relevant acceptor).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are clients, such as the .NET client with the AMQP protocol, do not support the failover protocol OOTB (here is also an &lt;a href="https://github.com/Azure/amqpnetlite/blob/master/Examples/Reconnect/ReconnectSender/ReconnectSender.cs" target="_blank" rel="noopener noreferrer"&gt;example&lt;/a&gt; showing how to mitigate this limitation). Using a load balancer helps with these clients.&lt;/p&gt; &lt;h4&gt;Apache Qpid&lt;/h4&gt; &lt;p&gt;Apache Qpid can act as an intelligent load balancer for the AMQP protocol only. It supports closest-, lowest latency-, and multicasting-type distributions. You will need to run multiple instances of Qpid to make it HA. That means the clients have to be configured to use multiple IPs. Qpid can also support many topologies, and allow having connections from more secure to less secure directions rather than the other way.&lt;/p&gt; &lt;p&gt;Qpid comes into its own in a geographically-spread meshing message where clients do not know the location of each other and any of the brokers they might be sending messages to, bi-directional messaging beyond the firewall, and building redundant messaging network routes. It&amp;#8217;s also easy to scale the number of brokers without changing the clients, and the topology can change without a change to the clients as well (dynamic messaging infrastructure).&lt;/p&gt; &lt;p&gt;You can also use Qpid to create multiple brokers sharding an address without the need to use broker clustering, but this feature is only useful if message ordering is not that important, or to act as a client connection concatenator (especially useful for IoT scenarios).&lt;/p&gt; &lt;h4&gt;Client-side load balancing&lt;/h4&gt; &lt;p&gt;Using a load balancer is not required in reality. You can configure messaging clients to connect to a broker cluster directly. A client can connect to a single broker and discover all other brokers, changing topologies, etc. Consider what happens if the single broker the client is trying to connect is down. For the answer, a list of broker IPs can be passed, and custom load balancing strategies implemented.&lt;/p&gt; &lt;p&gt;Client-side load balancing has advantages: The client can publish to multiple brokers and perform load balancing. This feature can be disabled if publishing to a single broker is required. The downside here is that the client-side load balancing is a client-specific implementation, and the options mentioned here vary across clients.&lt;/p&gt; &lt;h2&gt;Clients&lt;/h2&gt; &lt;p&gt;With Artemis, there are multiple clients, protocols, and possible combinations. In terms of protocols, here are a few high-level pointers. Another thing to consider here is which protocol can be &lt;a href="https://access.redhat.com/articles/2791941#broker" target="_blank" rel="noopener noreferrer"&gt;converted&lt;/a&gt; to which protocols when consumers and producers use different wire protocols and clients. The protocol and client choices are unlikely to impact the broker architecture, but they will impact the client service development efforts, and this issue can easily turn into a mess.&lt;/p&gt; &lt;h3&gt;AMQP 1.0&lt;/h3&gt; &lt;p&gt;AMQP 1.0 should be the default starting option when possible. This option is one of the most tested and used. It is also cross-language, and the only supported option for .NET clients. Keep in mind that Interconnect (the enterprise version of Apache Qpid) supports AMQP 1.0 only, and if Interconnect is in the architecture, the clients have to use AMQP to interact with it.&lt;/p&gt; &lt;p&gt;A limitation of AMQP is that it does not offer XA transaction support&lt;/p&gt; &lt;h3&gt;Core&lt;/h3&gt; &lt;p&gt;The Core protocol is one of the most advanced, feature-rich, and tested protocols for Artemis. It is the only supported protocol when using EAP with embedded Artemis, and it is the recommended protocol when XA is required.&lt;/p&gt; &lt;h3&gt;OpenWire&lt;/h3&gt; &lt;p&gt;This protocol is here for legacy compatibility reasons with AMQ 6 (Apache ActiveMQ broker) clients. It is useful in situations when the client code cannot change, so you are stuck with OpenWire. An attractive point about this protocol is that it supports XA.&lt;/p&gt; &lt;h2&gt;Reference architectures&lt;/h2&gt; &lt;p&gt;Having identified requirements, dependencies, and specific constraints, the next step is coming up with possible deployment architectures. I’m a firm believer in the mantra, &amp;#8220;There is no reference architecture for the real world.&amp;#8221; Consequently, there is no simple process to follow and map the findings to a target architecture. It is the combination of all requirements, constraints, and possible compromises that lead to identifying the most suitable architecture for a customer.&lt;/p&gt; &lt;p&gt;For demonstration purposes, the following are common Artemis deployment topologies for AWS, on bare VMS instead of Kubernetes. The same topologies also apply for on-premise deployments where similar alternative infrastructure services are present. The considerations that apply to all of the deployments below are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Client-side load balancing or a load balancer can be used for all of these deployments.&lt;/li&gt; &lt;li&gt;Load balancers can be co-located with the broker, client, in a dedicated layer, or a combination of these.&lt;/li&gt; &lt;li&gt;Slave brokers can be kept in separate hosts as demonstrated below, or co-located with a master broker.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Non-clustered Apache Artemis with shared storage&lt;/h3&gt; &lt;p&gt;The simplest HA architecture for Artemis is a single master/slave cluster with shared storage. The example that follows is a scalable version of that set up with two separate master/slave clusters. Notice that there is no clustering (server-side message distribution or load balancing) between the masters. As a result, the clients need to decide which master/slave cluster to use.&lt;/p&gt; &lt;h4&gt;Pros&lt;/h4&gt; &lt;p&gt;The pros of this approach are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It is a simple but highly available Artemis configuration and operational model.&lt;/li&gt; &lt;li&gt;It is the same topology as in Apache ActiveMQ with master/slave.&lt;/li&gt; &lt;li&gt;There is no possibility for split-brain, no stuck messages, and message order guaranteed.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Cons&lt;/h4&gt; &lt;p&gt;The cons are that this approach requires a shared file system or database, which has an additional cost. Typically, database-based storage is expected to perform worse than file-based storage.&lt;/p&gt; &lt;h4&gt;Other notes&lt;/h4&gt; &lt;p&gt;Additional notes include the fact that journal high availability is achieved through file system or database (AWS EFS or RDS ) data replication. Optionally, masters can be clustered for message distribution, load balancing, and scalability. The number of master/slave pairs can vary (there are two in Figure 3), and scaling is achieved by adding more master/slave pairs and using client-side partitioning.&lt;/p&gt; &lt;p&gt;Also, in the case of VM or DC failure, it ensures HA.&lt;/p&gt; &lt;div id="attachment_665377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df17053ab35c.png"&gt;&lt;img aria-describedby="caption-attachment-665377" class="wp-image-665377 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df17053ab35c-1024x976.png" alt="Apache Artemis with a shared file and database store." width="640" height="610" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df17053ab35c-1024x976.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df17053ab35c-300x286.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df17053ab35c-768x732.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-665377" class="wp-caption-text"&gt;Figure 3: Apache Artemis with a shared file and database store.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Clustered Apache Artemis with shared storage&lt;/h3&gt; &lt;p&gt;In this topology, we have three master/slave pairs, ensuring HA. In addition, all of the masters are clustered and provide server-side load balancing and message distribution. In this setup, the clients can connect to any member of the cluster and exchange messages. Such a cluster can also scale and change topology without affecting client configuration.&lt;/p&gt; &lt;h4&gt;Pros&lt;/h4&gt; &lt;p&gt;The pros of this option are that it offers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The same topology as in Apache ActiveMQ with master/slave and Network-of-Brokers.&lt;/li&gt; &lt;li&gt;Server-side message distribution and load balancing.&lt;/li&gt; &lt;li&gt;No possibility for split-brain scenarios.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Cons&lt;/h4&gt; &lt;p&gt;The cons are that it requires a shared file system or database, which has an additional cost. Typically, database-based storage is expected to perform worse than file-based storage.&lt;/p&gt; &lt;h4&gt;Other notes&lt;/h4&gt; &lt;p&gt;With this approach, journal high availability is achieved through file system or database (AWS EFS/RDS ) data replication. Optionally, masters can be non-clustered to prevent server-side load balancing. The number of master/slave pairs can vary (there are three in Figure 4), and scaling is achieved by adding more master/slave pairs transparently to the clients.&lt;/p&gt; &lt;p&gt;Finally, this approach ensures HA in the case of VM or DC failure.&lt;/p&gt; &lt;div id="attachment_665387" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171079a67a.png"&gt;&lt;img aria-describedby="caption-attachment-665387" class="wp-image-665387 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171079a67a-1024x713.png" alt="Apache Artemis with a shared file and database store." width="640" height="446" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171079a67a-1024x713.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171079a67a-300x209.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171079a67a-768x535.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-665387" class="wp-caption-text"&gt;Figure 4: Apache Artemis with a shared file and database store.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Clustered Apache Artemis with replication&lt;/h3&gt; &lt;p&gt;This architecture is a variation of the previous one, where we replace shared storage between Master and slave with replication. As such, this architecture has all of the benefits of server-side load-balancing and transparency for the clients. An added benefit of this architecture is that it does not require a highly-available shares storage layer. Instead, the brokers replicate the data.&lt;/p&gt; &lt;h4&gt;Pros&lt;/h4&gt; &lt;p&gt;The pros of this approach are that:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Data replication is performed by the broker, not by the infrastructure services.&lt;/li&gt; &lt;li&gt;There is no extra cost or dependency on the infrastructure for journal replication.&lt;/li&gt; &lt;li&gt;It offers scalable and highly available messaging infrastructure.&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Cons&lt;/h4&gt; &lt;p&gt;The cons are that:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Replication is sensitive to network latency, opening the possibility of split-brain scenarios. Notice that the replication in Figure 4 is within the same DC.&lt;/li&gt; &lt;li&gt;Compared to other options, this one has complex configuration and operational models.&lt;/li&gt; &lt;li&gt;It requires a minimum of three master and three slave brokers (as in the diagram below).&lt;/li&gt; &lt;/ul&gt; &lt;h4&gt;Other notes&lt;/h4&gt; &lt;p&gt;With this approach:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The number of master/slave pairs can be different (odd number required).&lt;/li&gt; &lt;li&gt;Optionally, server-side message distribution and load balancing can be disabled.&lt;/li&gt; &lt;li&gt;It ensures HA in the case of VM failure, but not in the case of DC failure.&lt;/li&gt; &lt;li&gt;It requires a quorum and a certain number of brokers to be alive.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_665397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df1717ae59b3.png"&gt;&lt;img aria-describedby="caption-attachment-665397" class="wp-image-665397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df1717ae59b3-1024x703.png" alt="Apache Artemis with replication." width="640" height="439" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df1717ae59b3-1024x703.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df1717ae59b3-300x206.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df1717ae59b3-768x527.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-665397" class="wp-caption-text"&gt;Figure 5: Apache Artemis with replication.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Capacity planning&lt;/h2&gt; &lt;p&gt;The numbers and ranges shown in Figure 5 are provided only as a guide and starting point. Depending on the use case, you might have to scale up or down your individual architectural components.&lt;/p&gt; &lt;div id="attachment_665407" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171f0b6138.png"&gt;&lt;img aria-describedby="caption-attachment-665407" class="wp-image-665407 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171f0b6138-1024x363.png" alt="Example sizing and considerations for the messaging components." width="640" height="227" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171f0b6138-1024x363.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171f0b6138-300x106.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df171f0b6138-768x272.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-665407" class="wp-caption-text"&gt;Figure 5: Example sizing and considerations for the messaging components.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Over the years, I have hardly seen two messaging architectures that are absolutely the same. Every organization has something unique in the way they manage their infrastructure and organize their teams, and that inevitably ends up reflected in the resulting architectures. Your job as a consultant or architect is to find the most suitable architecture within the current constraints, and educate and guide the customer towards the best possible outcome. There is no right or wrong architecture, but deliberate trade-off commitments in a context.&lt;/p&gt; &lt;p&gt;In this article, I tried to cover as many areas of Artemis as possible from an architecturally significant point of view. But by doing so, I had to be opinionated, ignore other areas, and emphasize what I think is significant based on my experience. I hope you find it useful and learned something from it. If that is the case, say something on &lt;a href="http://twitter.com/bibryam" target="_blank" rel="noopener noreferrer"&gt;Twitter&lt;/a&gt; and spread the word.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#38;linkname=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F10%2Farchitecting-messaging-solutions-with-apache-activemq-artemis%2F&amp;#038;title=Architecting%20messaging%20solutions%20with%20Apache%20ActiveMQ%20Artemis" data-a2a-url="https://developers.redhat.com/blog/2020/01/10/architecting-messaging-solutions-with-apache-activemq-artemis/" data-a2a-title="Architecting messaging solutions with Apache ActiveMQ Artemis"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/10/architecting-messaging-solutions-with-apache-activemq-artemis/"&gt;Architecting messaging solutions with Apache ActiveMQ Artemis&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/x7Aid60qMeM" height="1" width="1" alt=""/&gt;</content><summary>As an architect in the Red Hat Consulting team, I’ve helped countless customers with their integration challenges over the last six years. Recently, I had a few consulting gigs around Red Hat AMQ 7 Broker (the enterprise version of Apache ActiveMQ Artemis), where the requirements and outcomes were similar. That similarity made me think that the whole requirement identification process and can be m...</summary><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2020-01-10T08:12:59Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/10/architecting-messaging-solutions-with-apache-activemq-artemis/</feedburner:origLink></entry><entry><title>This Week in JBoss (9th January 2020) - Happy New Year Everybody!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/seKO44PmQzE/this-week-in-jboss-9th-january-2020-happy-new-year-everybody" /><category term="amazon aws" scheme="searchisko:content:tags" /><category term="camel-core" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="jgroups" scheme="searchisko:content:tags" /><category term="Kafka" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="oauth" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><author><name>Romain Pelisse</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_9th_january_2020_happy_new_year_everybody</id><updated>2020-01-09T12:00:50Z</updated><published>2020-01-09T12:00:50Z</published><content type="html">&lt;!-- [DocumentBodyStart:876f8e23-5188-4d3b-8ad0-1a61478f3063] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;&lt;em&gt;For this very first editorial of 2020, let us wish you all a Happy New Year! We hope you&amp;#8217;ll have another excellent year within the JBoss community and the editorial will keep you up to date like it did in the last years. With that out of the way, let&amp;#8217;s carry on and jump into this week&amp;#8217;s issue, starting, of course, with an update on Quarkus!&lt;/em&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Quarkus... Godspeed!&lt;/h1&gt;&lt;p&gt;As the new year arrives, we're happy to report that our latest (and very promising) project, Quarkus is still going strong. It just released its &lt;a class="jive-link-external-small" href="https://quarkus.io/blog/quarkus-1-1-1-final-released/http://" rel="nofollow"&gt;version 1.1.1&lt;/a&gt; but also the framework is gaining traction, especially in the context app developed for the clouds. If you want to know more, take a look at this article titled &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/26/see-the-magic-behind-quarkus-the-cloud-native-java-framework/" rel="nofollow"&gt;See the magic behind Quarkus, the cloud-native Java framework&lt;/a&gt;. It's also interesting to see that there Quarkus, like Wildfly, does not forbid the use of the popular Spring framework, but also integrate wells into Kubernatives! More on this in this other article &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/02/kubernetes-native-spring-apps-on-quarkus/" rel="nofollow"&gt;Kubernetes-native Spring apps on Quarkus&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;center&gt;&lt;p style="font-size: 8px; font-style: italic;"&gt;&lt;a href="https://farm8.staticflickr.com/7650/17144619096_b0d452ee0a_b.jpg"&gt;&lt;img alt="15-04-2015 Quark Chromosphere" src="https://farm8.staticflickr.com/7650/17144619096_b0d452ee0a_b.jpg" style="display: block;"/&gt;&lt;/a&gt;&lt;a class="jive-link-external-small" href="https://www.flickr.com/photos/99031127@N08/17144619096" rel="nofollow"&gt;Quark Chromosphere"&lt;/a&gt;&lt;span&gt; by &lt;a class="jive-link-external-small" href="https://www.flickr.com/photos/99031127@N08" rel="nofollow"&gt;ewanhobbs99&lt;/a&gt;&lt;/span&gt; is licensed under &lt;a class="jive-link-external-small" href="https://creativecommons.org/licenses/by-nc-nd/2.0/?ref=ccsearch&amp;amp;atype=html" rel="nofollow"&gt;CC BY-NC-ND 2.0&lt;/a&gt;&lt;a href="https://creativecommons.org/licenses/by-nc-nd/2.0/?ref=ccsearch&amp;amp;atype=html" rel="nofollow"&gt;&lt;img src="https://search.creativecommons.org/static/img/cc_icon.svg" style="height: 10px; margin-right: 3px; display: inline-block;"/&gt;&lt;img src="https://search.creativecommons.org/static/img/cc-by_icon.svg" style="height: 10px; margin-right: 3px; display: inline-block;"/&gt;&lt;img src="https://search.creativecommons.org/static/img/cc-nc_icon.svg" style="height: 10px; margin-right: 3px; display: inline-block;"/&gt;&lt;img src="https://search.creativecommons.org/static/img/cc-nd_icon.svg" style="height: 10px; margin-right: 3px; display: inline-block;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/center&gt;&lt;h1&gt;Techbytes&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Bela Ban, the main developer of JGroups does not blog often, but&amp;#160; when it does, it's generally very interesting, in-depth articles regarding clustering and network development. His latest installment does not break with the pattern and led you into the complex, but fascinating use case of&lt;a class="jive-link-external-small" href="http://belaban.blogspot.com/2019/12/spanning-jgroups-kubernetes-based.html" rel="nofollow"&gt; Spanning JGroups Kubernetes-based clusters across Google and Amazon clouds&lt;/a&gt;. A must read for the week! Still on the topic of Kubernetes clusters, maybe you want to discover &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/02/kubernetes-native-spring-apps-on-quarkus/" rel="nofollow"&gt;Skupper.io: Let your services communicate across Kubernetes clusters&lt;/a&gt;? Or maybe you are a Kafka user, then your interest will be picked by this article on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/02/kubernetes-native-spring-apps-on-quarkus/" rel="nofollow"&gt;Serverless Kafka on Kubernetes.&lt;/a&gt;&lt;/p&gt;&lt;center&gt;&lt;a href="https://1.bp.blogspot.com/-yrs8If-J8a0/XgoYQyGVWxI/AAAAAAABSl8/bzaVzzzkFtUYvW-CevaQSYkSCtatWVyJgCLcBGAsYHQ/s640/xsite.png"&gt;&lt;img src="https://1.bp.blogspot.com/-yrs8If-J8a0/XgoYQyGVWxI/AAAAAAABSl8/bzaVzzzkFtUYvW-CevaQSYkSCtatWVyJgCLcBGAsYHQ/s640/xsite.png"/&gt;&lt;/a&gt;&lt;/center&gt;&lt;center&gt;&lt;/center&gt;&lt;p&gt;Leaving Kubernetes behind, we also have a couple of other interesting articles being released in the last week. The first one covers &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/03/dynamic-case-management-in-the-event-driven-era/" rel="nofollow"&gt;Dynamic case management in the event-driven era&lt;/a&gt;, so a rather high-level view, while the second one drills down on a more pragmatic problem discussing &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/27/role-based-access-control-behind-a-proxy-in-an-oauth-access-delegation/" rel="nofollow"&gt;Role-based access control behind a proxy in an OAuth access delegation&lt;/a&gt;. Last but not the least, we have another "in-depth" article discussing &lt;a class="jive-link-external-small" href="https://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core.html" rel="nofollow"&gt;camel-core optimizations coming&lt;/a&gt; up in the next versions.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Evangelist's Corner&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;As always, our evangelists keep releasing new demo and content to help people discover and use the latest version of the JBoss Community projects. In the last weeks, &lt;a class="jive-link-external-small" href="http://www.schabell.org/2020/01/code-ready-containers-decision-management-developer-tools-update.html" rel="nofollow"&gt;Eric D. Schabell released an article titled Code Ready Containers on Decision Management developer tools update&lt;/a&gt;, but also another on titled &lt;a class="jive-link-external-small" href="https://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core.html" rel="nofollow"&gt;2019 in review - Open career and portfolio architecture&lt;/a&gt;. Go check them out!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;D&amp;eacute;caf'&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Kubernetes has been a very trendy topic for the last month. Actually, this very editorial features none less than three different articles relating to it! As people maybe interested in those while not wanting to fish them out of the content above, I've regrouped them all here. First we have the passionating article from Bela Ban on &lt;a class="jive-link-external-small" href="http://belaban.blogspot.com/2019/12/spanning-jgroups-kubernetes-based.html" rel="nofollow"&gt;Spanning JGroups Kubernetes-based clusters across Google and Amazon clouds&lt;/a&gt;, closely followed by the one on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/02/kubernetes-native-spring-apps-on-quarkus/" rel="nofollow"&gt;Skupper.io: Let your services communicate across Kubernetes clusters&lt;/a&gt; and, of course, the one on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/30/serverless-kafka-on-kubernetes/" rel="nofollow"&gt;Serverless Kafka on Kubernetes&lt;/a&gt; ! Enjoy!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;em&gt;That's all for another edition of the JBoss Editorial, please join us again for more exciting development from the JBoss Communities.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:876f8e23-5188-4d3b-8ad0-1a61478f3063] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/seKO44PmQzE" height="1" width="1" alt=""/&gt;</content><summary>For this very first editorial of 2020, let us wish you all a Happy New Year! We hope you’ll have another excellent year within the JBoss community and the editorial will keep you up to date like it did in the last years. With that out of the way, let’s carry on and jump into this week’s issue, starting, of course, with an update on Quarkus!   Quarkus... Godspeed! As the new year arrives, we're hap...</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2020-01-09T12:00:50Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2020/01/09/this-week-in-jboss-9th-january-2020-happy-new-year-everybody</feedburner:origLink></entry><entry><title>Debugging applications within Red Hat OpenShift containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/s6g_koN-osU/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="debugging" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="Red Hat CodeReady Containers" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="universal base images" scheme="searchisko:content:tags" /><author><name>Serhei Makarov</name></author><id>searchisko:content:id:jbossorg_blog-debugging_applications_within_red_hat_openshift_containers</id><updated>2020-01-09T08:06:04Z</updated><published>2020-01-09T08:06:04Z</published><content type="html">&lt;p&gt;When debugging an application within a &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; container, it is important to keep in mind that the Linux environment within the container is subject to various constraints. Because of these constraints, the full functionality of debugging tools might not be available:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;An unprivileged OpenShift container is restricted from accessing kernel interfaces that are required by some low-level debugging tools.&lt;/li&gt; &lt;/ul&gt; &lt;blockquote&gt;&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; Almost all applications on OpenShift run in unprivileged containers. Unprivileged containers allow the use of standard debugging tools such as &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Server.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;gdbserver&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://strace.io/" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;strace&lt;/code&gt;&lt;/a&gt;. Examples of debugging tools that cannot be used in unprivileged containers include &lt;a href="https://perf.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;perf&lt;/code&gt;&lt;/a&gt;, which requires access to the kernel’s &lt;code&gt;perf_events&lt;/code&gt; interface, and &lt;a href="https://sourceware.org/systemtap" target="_blank" rel="noopener noreferrer"&gt;SystemTap&lt;/a&gt;, which depends on the kernel’s module-loading functionality.&lt;/p&gt;&lt;/blockquote&gt; &lt;ul&gt; &lt;li&gt;Debug information for system packages within OpenShift containers is not accessible. There is ongoing work (as part of the &lt;a href="https://sourceware.org/elfutils/" target="_blank" rel="noopener noreferrer"&gt;elfutils&lt;/a&gt; project) to develop &lt;a href="https://developers.redhat.com/blog/2019/10/14/introducing-debuginfod-the-elfutils-debuginfo-server/"&gt;a file server for debug information (&lt;code&gt;debuginfod&lt;/code&gt;)&lt;/a&gt;, which would make such access possible.&lt;/li&gt; &lt;li&gt;The set of packages in an OpenShift container is fixed ahead of time, when the corresponding container image is built. Once a container is running, no additional packages can be installed. A few debugging tools are preinstalled in commonly used container base images, but any other tools must be added when the container image build process is configured.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To successfully debug a containerized application, it is necessary to understand these constraints and how they determine which debugging tools can be used.&lt;br /&gt; &lt;span id="more-663287"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="debugging-tools-preinstalled-in-container-images"&gt;Debugging tools preinstalled in container images&lt;/h2&gt; &lt;p&gt;Most container base images for the OpenShift platform include at least a minimal level of preinstalled debugging functionality. General-purpose base images such as the &lt;a href="https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image" target="_blank" rel="noopener noreferrer"&gt;Red Hat Enterprise Linux (RHEL) Universal Base Image&lt;/a&gt; include the &lt;code&gt;gdbserver&lt;/code&gt; component of the GDB debugger, while container base images intended for higher-level language runtimes usually include debugging functionality specific to those runtimes.&lt;/p&gt; &lt;p&gt;The general-purpose Red Hat Enterprise Linux container base images include the &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Server.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;gdbserver&lt;/code&gt;&lt;/a&gt; component of the commonly-used GDB debugger. Gdbserver can be used by configuring an interactive GDB session that runs outside the OpenShift cluster to pass remote commands to a &lt;code&gt;gdbserver&lt;/code&gt; instance within a container. This &lt;code&gt;gdbserver&lt;/code&gt; instance has direct access to the containerized application. In response to remote commands from the GDB session, &lt;code&gt;gdbserver&lt;/code&gt; will collect information from the application and pass it back to the GDB session:&lt;/p&gt; &lt;p&gt;&lt;img class="wp-image-663337 size-full aligncenter" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/openshift-debug-fig1-gdbserver.png" alt="Diagram of GDB outside the OpenShift container and gdbserver inside the container." width="367" height="213" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/openshift-debug-fig1-gdbserver.png 367w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/openshift-debug-fig1-gdbserver-300x174.png 300w" sizes="(max-width: 367px) 100vw, 367px" /&gt;&lt;/p&gt; &lt;p&gt;The following debugging session illustrates how &lt;code&gt;gdbserver&lt;/code&gt; can be attached to a program in a container based on the &lt;a href="https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image" target="_blank" rel="noopener noreferrer"&gt;Red Hat Universal Base Image&lt;/a&gt; (UBI). The commands in this session should also work with containers based on earlier Red Hat Enterprise Linux container base images. This procedure was tested on an OpenShift 4.2.8 cluster managed with &lt;a href="https://developers.redhat.com/products/codeready-containers/download" target="_blank" rel="noopener noreferrer"&gt;CodeReady Containers 1.2.0&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;We begin the session by creating a container:&lt;/p&gt; &lt;pre&gt;$ oc new-app --name='ubi8-example' nodeshift/ubi8-s2i-web-app:latest~https://github.com/lholmquist/react-web-app &lt;/pre&gt; &lt;p&gt;Obtain the name of the container with the &lt;code&gt;oc get pods&lt;/code&gt; operation:&lt;/p&gt; &lt;pre&gt;$ oc get pods NAME READY STATUS RESTARTS AGE ubi8-example-1-22wlk 1/1 Running 0 2m45s ubi8-example-1-build 0/1 Completed 0 5m20s ubi8-example-1-deploy 0/1 Completed 0 2m53s &lt;/pre&gt; &lt;p&gt;To verify that the container includes the &lt;code&gt;gdbserver&lt;/code&gt; package, use the &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-remote-commands.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;oc exec&lt;/code&gt;&lt;/a&gt; operation to execute an &lt;code&gt;rpm&lt;/code&gt; command within the container:&lt;/p&gt; &lt;pre&gt;$ oc exec -it ubi8-example-1-22wlk -- rpm -qa | grep gdbserver gdb-gdbserver-8.2-6.el8.x86_64 &lt;/pre&gt; &lt;p&gt;We need the process ID of the program we want to debug. To obtain it, execute a &lt;code&gt;ps&lt;/code&gt; command within the container:&lt;/p&gt; &lt;pre&gt;$ oc exec -it ubi8-example-1-22wlk -- ps -ax PID TTY STAT TIME COMMAND 1 ? Ss 0:00 /bin/bash /usr/libexec/s2i/run 9 ? Sl 0:00 /usr/bin/node /usr/bin/npx serve -s /opt/app-root/output -l 48 pts/0 Rs+ 0:00 ps -ax &lt;/pre&gt; &lt;p&gt;Next, launch a local GDB session and connect to &lt;code&gt;gdbserver&lt;/code&gt; within the container:&lt;/p&gt; &lt;pre&gt;$ gdb (gdb) target extended-remote | oc exec -i ubi8-example-1-22wlk -- gdbserver --multi - Remote debugging using | oc exec -i ubi8-example-1-22wlk -- gdbserver --multi - Remote debugging using stdio &lt;/pre&gt; &lt;p&gt;Here, GDB is instructed to connect to a &lt;code&gt;gdbserver&lt;/code&gt; process in the container. This &lt;code&gt;gdbserver&lt;/code&gt; process is started with an &lt;code&gt;oc exec&lt;/code&gt; operation and configured to listen for commands on its standard input. The OpenShift infrastructure passes the standard input and standard output of the &lt;code&gt;gdbserver&lt;/code&gt; process over the network to the local GDB session.&lt;/p&gt; &lt;p&gt;Next, instruct GDB to attach to the main server process in the container, which is identified by the process ID we obtained earlier:&lt;/p&gt; &lt;pre&gt;(gdb) attach 9 Attaching to process 9 Attached; pid = 9 Reading /usr/bin/node from remote target... ... 0x00007fd1cb44228e in epoll_pwait () from target:/lib64/libc.so.6 &lt;/pre&gt; &lt;p&gt;At this point, GDB is ready to debug the process.&lt;/p&gt; &lt;h3 id="restrictions-on-gdb-functionality-within-openshift-containers"&gt;Restrictions on GDB functionality within OpenShift containers&lt;/h3&gt; &lt;p&gt;In a Red Hat OpenShift container, certain GDB functionality could be unavailable depending on how the container is configured.&lt;/p&gt; &lt;p&gt;For example, GDB functions that depend on access to debug information will be unavailable. Although &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/developer_guide/index#enabling-debugging_understanding-debuginfo-packages" target="_blank" rel="noopener noreferrer"&gt;debug information packages&lt;/a&gt; are available in many Linux distributions, including Red Hat Enterprise Linux, these packages can only be included in a container image ahead of time, and cannot be installed in an unprivileged container once that container is already running.&lt;/p&gt; &lt;p&gt;Nevertheless, there is a subset of GDB’s functions which can be used in the absence of debug information:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;GDB can &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Linespec-Locations.html#Linespec-Locations" target="_blank" rel="noopener noreferrer"&gt;trigger breakpoints and tracepoints&lt;/a&gt; at function entry points.&lt;/li&gt; &lt;li&gt;GDB can use the mechanism of &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Static-Probe-Points.html" target="_blank" rel="noopener noreferrer"&gt;statically-defined tracing&lt;/a&gt; (SDT) markers in order to trigger breakpoints or tracepoints on various high-level events in the program.&lt;/li&gt; &lt;li&gt;GDB can &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Core-File-Generation.html#Core-File-Generation" target="_blank" rel="noopener noreferrer"&gt;generate a core file&lt;/a&gt; of the program’s memory. The core file can be saved and inspected outside of the OpenShift environment.&lt;/li&gt; &lt;li&gt;GDB can &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Stack.html#Stack" target="_blank" rel="noopener noreferrer"&gt;obtain stack traces&lt;/a&gt; from the program.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The following example shows how the command &lt;code&gt;thread apply all bt&lt;/code&gt; can be used to obtain a stack trace of each thread in a process:&lt;/p&gt; &lt;pre&gt; (gdb) attach 9 (gdb) thread apply all bt Thread 11 (Thread 9.19): #0 0x00007fd1cb71747c in pthread_cond_wait@@GLIBC_2.3.2 () from target:/lib64/libpthread.so.0 #1 0x00005585ba200d7d in uv_cond_wait () #2 0x00005585ba1eea22 in worker () #3 0x00007fd1cb7112de in start_thread () from target:/lib64/libpthread.so.0 #4 0x00007fd1cb442133 in clone () from target:/lib64/libc.so.6 ... Thread 2 (Thread 9.10): #0 0x00007fd1cb44228e in epoll_pwait () from target:/lib64/libc.so.6 #1 0x00005585ba203f7e in uv.io_poll () #2 0x00005585ba1f3ea0 in uv_run () #3 0x00005585ba10faa4 in node::WorkerThreadsTaskRunner::DelayedTaskScheduler::Start()::{lambda(void*)#1}::_FUN(void*) () #4 0x00007fd1cb7112de in start_thread () from target:/lib64/libpthread.so.0 #5 0x00007fd1cb442133 in clone () from target:/lib64/libc.so.6 Thread 1 (Thread 9.9): #0 0x00007fd1cb44228e in epoll_pwait () from target:/lib64/libc.so.6 #1 0x00005585ba203f7e in uv.io_poll () #2 0x00005585ba1f3ea0 in uv_run () #3 0x00005585ba0e3c7a in node::NodeMainInstance::Run() () #4 0x00005585ba072eb4 in node::Start(int, char**) () #5 0x00007fd1cb369873 in __libc_start_main () from target:/lib64/libc.so.6 #6 0x00005585ba00f14e in _start () &lt;/pre&gt; &lt;p&gt;Secondly, GDB functions that require stopping the application are incompatible with periodic health checks. If a container has been configured to run &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-health.html" target="_blank" rel="noopener noreferrer"&gt;periodic health checks&lt;/a&gt;, the OpenShift infrastructure will periodically send a message to the containerized application to verify that it is running. If the application has been paused by GDB, it will fail to respond to the message and OpenShift will restart the container on the assumption that the application has crashed. This restart will interrupt the debugging session and reset the application state. In this situation, it is not feasible to pause the program for an extended period of time. For such situations, GDB supports background execution and dynamic tracing. GDB’s &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Background-Execution.html#Background-Execution" target="_blank" rel="noopener noreferrer"&gt;background execution commands&lt;/a&gt;, such as &lt;code&gt;attach&amp;#38;&lt;/code&gt;, allow GDB to attach to a program without pausing it. GDB’s &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Tracepoints.html#Tracepoints" target="_blank" rel="noopener noreferrer"&gt;tracepoint facilities&lt;/a&gt; can collect data while the program continues running.&lt;/p&gt; &lt;h3 id="debugging-tools-for-higher-level-languages"&gt;Debugging tools for higher-level languages&lt;/h3&gt; &lt;p&gt;Container base images that include higher-level language runtimes might include corresponding debugging functionality. For example, Java container images include support for the Java remote debugging protocol, and Node.js container images include the Node.js inspector agent. An &lt;a href="https://developers.redhat.com/blog/2017/12/19/debug-java-openshift-vscode-cdk/"&gt;earlier article by Jeff Maury&lt;/a&gt; describes how to enable and use debugging features in container images for the Java runtime, and an &lt;a href="https://developers.redhat.com/blog/2018/05/15/debug-your-node-js-application-on-openshift-with-chrome-devtools/"&gt;article by Lucas Holmquist&lt;/a&gt; describes how to enable and use debugging features in container images for Node.js applications.&lt;/p&gt; &lt;p&gt;Although many commonly used container base images include debugging facilities, there is no absolute guarantee that a container base image will include them. It is necessary to examine the contents of a container image in order to understand the included debugging facilities and determine whether additional packages need to be installed.&lt;/p&gt; &lt;h2 id="installing-debugging-tools-at-container-image-build-time"&gt;Installing debugging tools at container image build time&lt;/h2&gt; &lt;p&gt;There are debugging tools that can be used within containers but are not preinstalled in container base images. Tools such as &lt;a href="https://strace.io/" target="_blank" rel="noopener noreferrer"&gt;strace&lt;/a&gt; or &lt;a href="https://valgrind.org/" target="_blank" rel="noopener noreferrer"&gt;Valgrind&lt;/a&gt; must be included in a container during the container image build process.&lt;/p&gt; &lt;p&gt;In order to add a debugging tool to a container, the container image build process must be configured to perform additional package installation commands. Whether or not package installation is permitted during the image build process depends on the method being used to build the container image. OpenShift provides several methods of building container images. These methods are called &lt;a href="https://docs.openshift.com/container-platform/4.2/builds/build-strategies.html" target="_blank" rel="noopener noreferrer"&gt;build strategies&lt;/a&gt;. Currently, OpenShift supports the Dockerfile, Source-to-Image (S2I), Pipeline, and Custom build strategies. Not all build strategies allow package installation: Of the most commonly-used strategies, the Dockerfile strategy permits package installation but the S2I strategy does not, because an S2I build process builds the container image in an unprivileged environment. A build process within an unprivileged environment lacks the ability to invoke package installation commands.&lt;/p&gt; &lt;p&gt;Debugging tool packages installed during the Dockerfile build process for a container image are included in that container image. For example, the following Dockerfile commands specify a container that includes the &lt;code&gt;strace&lt;/code&gt; package:&lt;/p&gt; &lt;pre&gt;FROM registry.access.redhat.com/ubi8/ubi-init RUN yum -y install strace &lt;/pre&gt; &lt;h2 id="debugging-tools-requring-privileged-containers"&gt;Debugging tools requiring privileged containers&lt;/h2&gt; &lt;p&gt;A debugging tool cannot operate within an OpenShift container if the container does not have the privileges to access the operating system functionality required by the tool. For example, the &lt;a href="https://sourceware.org/systemtap" target="_blank" rel="noopener noreferrer"&gt;SystemTap&lt;/a&gt; default kernel module backend cannot operate in containers that lack the privileges to load kernel modules. Similarly, &lt;a href="https://perf.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener noreferrer"&gt;perf&lt;/a&gt; requires access to the kernel &lt;code&gt;perf_events&lt;/code&gt; interface, and &lt;a href="https://www.iovisor.org/technology/bcc" target="_blank" rel="noopener noreferrer"&gt;bcc&lt;/a&gt; requires access to BPF tracing functionality. These functions are not available within unprivileged OpenShift containers. In general, a debugging tool that requires elevated privileges can only be used within a &lt;a href="https://docs.openshift.com/container-platform/4.2/authentication/managing-security-context-constraints.html" target="_blank" rel="noopener noreferrer"&gt;privileged container&lt;/a&gt; created by a cluster administrator.&lt;/p&gt; &lt;p&gt;In general, to determine whether a debugging tool can be used within an OpenShift container, it is necessary to investigate the set of operating system interfaces the tool relies on, and then to identify whether the OpenShift container has sufficient privileges to access these interfaces. Commonly used debugging tools such as &lt;code&gt;gdbserver&lt;/code&gt; or &lt;code&gt;strace&lt;/code&gt; are able to operate within unprivileged OpenShift containers because they rely on the &lt;code&gt;ptrace()&lt;/code&gt; system call, which is available by default in unprivileged containers.&lt;/p&gt; &lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article gave a summary of various options for debugging a containerized application on OpenShift. Currently, in order to troubleshoot a running OpenShift application, it is necessary to anticipate the set of debugging tools that might be required, and steps must be taken ahead of time to ensure that these debugging tools will be present within the container.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#38;linkname=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F09%2Fdebugging-applications-within-red-hat-openshift-containers%2F&amp;#038;title=Debugging%20applications%20within%20Red%20Hat%20OpenShift%20containers" data-a2a-url="https://developers.redhat.com/blog/2020/01/09/debugging-applications-within-red-hat-openshift-containers/" data-a2a-title="Debugging applications within Red Hat OpenShift containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/09/debugging-applications-within-red-hat-openshift-containers/"&gt;Debugging applications within Red Hat OpenShift containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/s6g_koN-osU" height="1" width="1" alt=""/&gt;</content><summary>When debugging an application within a Red Hat OpenShift container, it is important to keep in mind that the Linux environment within the container is subject to various constraints. Because of these constraints, the full functionality of debugging tools might not be available: An unprivileged OpenShift container is restricted from accessing kernel interfaces that are required by some low-level de...</summary><dc:creator>Serhei Makarov</dc:creator><dc:date>2020-01-09T08:06:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/09/debugging-applications-within-red-hat-openshift-containers/</feedburner:origLink></entry><entry><title>Code Ready Containers - Process Automation developer tools update</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FLyzxErk1D0/code-ready-containers-process-automation-developer-tools-update.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="CodeReadyContainers" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-code_ready_containers_process_automation_developer_tools_update</id><updated>2020-01-09T06:00:01Z</updated><published>2020-01-09T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-5KUGXJv8P2U/XhLsZAjqeeI/AAAAAAAAw1o/GBR0PXlT4joyYY9qk0x2ao6gpdO9FOJ-wCNcBGAsYHQ/s1600/rhcs-rhpam-pod-ocp.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="code ready containers" border="0" data-original-height="888" data-original-width="1600" height="177" src="https://1.bp.blogspot.com/-5KUGXJv8P2U/XhLsZAjqeeI/AAAAAAAAw1o/GBR0PXlT4joyYY9qk0x2ao6gpdO9FOJ-wCNcBGAsYHQ/s320/rhcs-rhpam-pod-ocp.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;For some time now we've been working on updating your experience using Code Ready Containers, a container platform installation for your local machine, by providing interesting developer tooling and project examples.&lt;br /&gt;&lt;br /&gt;There is no better way to learn about container technologies, container platforms, and container-based application development than getting hands-on with great open technologies.&lt;br /&gt;&lt;br /&gt;This example is the latest version of the Red Hat Process Automation Manager, version 7.5, installed on OpenShift Container Platform (either your own installation or using our Code Ready Containers installation).&lt;br /&gt;&lt;br /&gt;Get started today with processes, user tasks, forms, rules, and business logic in just a few simple steps, as follows.&lt;br /&gt;&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 data-sourcepos="1:1-3:130" style="text-align: left;"&gt;AppDev in Cloud with Red Hat Process Automation Manager Install Demo&lt;/h3&gt;&lt;div data-sourcepos="3:1-4:70" dir="auto"&gt;This demo is to install Red Hat Process Automation Manager in the Cloud based on leveraging any Red Hat OpenShift Container Platform. It delivers a fully functioning Decision Manager containerized on OpenShift Container Platform.&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div data-sourcepos="3:1-4:70" dir="auto"&gt;&lt;a href="https://1.bp.blogspot.com/-jsUfUHC2PkA/XhLsYKlHm0I/AAAAAAAAw1g/YFJSBjbaYZcJxR9FcmIIythTSznl1SSQQCEwYBhgL/s1600/rhcs-rhpam-build-ocp.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="code ready containers" border="0" data-original-height="833" data-original-width="1600" height="166" src="https://1.bp.blogspot.com/-jsUfUHC2PkA/XhLsYKlHm0I/AAAAAAAAw1g/YFJSBjbaYZcJxR9FcmIIythTSznl1SSQQCEwYBhgL/s320/rhcs-rhpam-build-ocp.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;h3 data-sourcepos="7:1-9:131" style="text-align: left;"&gt;Install on OpenShift Container Platform&lt;/h3&gt;&lt;div data-sourcepos="9:1-10:83" dir="auto"&gt;There are two options to install and run this project on the OpenShift Container Platform; use your own existing installation or to install on Code Ready Containers which provides you with a local OpenShift cluster.&lt;/div&gt;&lt;ol data-sourcepos="12:1-13:0" dir="auto"&gt;&lt;li data-sourcepos="12:1-13:0"&gt;Ensure you have an OpenShift container based installation, such as one of the following:&lt;/li&gt;&lt;/ol&gt;&lt;ul data-sourcepos="14:3-17:0" dir="auto"&gt;&lt;li data-sourcepos="14:3-15:0"&gt; &lt;div data-sourcepos="14:5-14:116"&gt;your own OpenShift installation, if using this you just need to pass the IP address to the init.{sh|bat} script. &lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="16:3-17:0"&gt; &lt;div data-sourcepos="16:5-16:95"&gt;&lt;a href="https://gitlab.com/redhatdemocentral/ocp-install-demo"&gt;Code Ready Containers Easy Install&lt;/a&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol data-sourcepos="18:1-23:0" dir="auto" start="2"&gt;&lt;li data-sourcepos="18:1-19:0"&gt; &lt;div data-sourcepos="18:4-18:146"&gt;&lt;a href="https://gitlab.com/redhatdemocentral/rhcs-rhpam-install-demo/-/archive/master/rhcs-rhpam-install-demo-master.zip" target="_blank"&gt;Download and unzip this demo.&lt;/a&gt;&lt;/div&gt;&lt;div data-sourcepos="18:4-18:146"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="20:1-21:0"&gt; &lt;div data-sourcepos="20:4-20:106"&gt;Download Red Hat JBoss EAP &amp;amp; Red Hat Process Automation Manager, add to installs directory (see installs/README).&lt;/div&gt;&lt;div data-sourcepos="20:4-20:106"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="22:1-23:0"&gt; &lt;div data-sourcepos="22:4-22:91"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges:&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre class="code highlight js-syntax-highlight plaintext dark" lang="plaintext"&gt;&lt;code&gt;&lt;span class="line" id="LC1" lang="plaintext"&gt; # If using your own installation just point to Openshift Container Platform IP Address&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC2" lang="plaintext"&gt; # as follows:&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC3" lang="plaintext"&gt; #&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC4" lang="plaintext"&gt; $ ./init.sh 192.168.99.100 # example for OCP.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre class="code highlight js-syntax-highlight plaintext dark" lang="plaintext"&gt;&lt;code&gt;&lt;span class="line" id="LC4" lang="plaintext"&gt;&amp;nbsp;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre class="code highlight js-syntax-highlight plaintext dark" lang="plaintext"&gt;&lt;code&gt;&lt;span class="line" id="LC4" lang="plaintext"&gt;&amp;nbsp;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre class="code highlight js-syntax-highlight plaintext dark" lang="plaintext"&gt;&lt;code&gt;&lt;span class="line" id="LC1" lang="plaintext"&gt; # If using Code Ready Containers or the Code Ready Containers Easy Install project, just add the cluster &lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC2" lang="plaintext"&gt; # address to HOST_IP variable found at the top of the init.{sh|bat} files, for example:&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC3" lang="plaintext"&gt; #&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC4" lang="plaintext"&gt; # HOST_IP=api.crc.testing &lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC5" lang="plaintext"&gt; # &lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC6" lang="plaintext"&gt; # Now just run the script without any IP address arguments and it picks up that hostname as follows:&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC7" lang="plaintext"&gt; #&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC8" lang="plaintext"&gt; $ ./init.sh&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;div data-sourcepos="42:1-42:140" dir="auto"&gt;&lt;a href="https://1.bp.blogspot.com/-vEsuIwWe5xg/XhLsYPZArnI/AAAAAAAAw1w/9NM0V6bfpYEUVxTBUf6R4kw2wloDArxSQCEwYBhgL/s1600/rhcs-rhpam-ocp.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-original-height="886" data-original-width="1600" height="177" src="https://1.bp.blogspot.com/-vEsuIwWe5xg/XhLsYPZArnI/AAAAAAAAw1w/9NM0V6bfpYEUVxTBUf6R4kw2wloDArxSQCEwYBhgL/s320/rhcs-rhpam-ocp.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div data-sourcepos="42:1-42:140" dir="auto"&gt;Now log in to Red Hat Process Automation Manager to start developing containerized process automation projects (the address will be generated by OCP):&lt;/div&gt;&lt;ul data-sourcepos="44:3-45:0" dir="auto"&gt;&lt;li data-sourcepos="44:3-45:0"&gt;Code Ready Container example: http:rhcs-rhpam-install-demo-appdev-in-cloud.apps-crc.testing/business-central ( u:erics / p:redhatpam1! )&lt;/li&gt;&lt;/ul&gt;&lt;div data-sourcepos="46:1-46:195" dir="auto"&gt;Not sure how to get started with Red Hat Decision Manager? Try one of these &lt;a href="https://bpmworkshop.gitlab.io/#/5" rel=" noreferrer noopener" target="_blank"&gt;online workshops&lt;/a&gt; to build a first project from scratch.&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=9GfFtYak0eM:efbUVIU2X9k:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=9GfFtYak0eM:efbUVIU2X9k:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=9GfFtYak0eM:efbUVIU2X9k:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=9GfFtYak0eM:efbUVIU2X9k:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=9GfFtYak0eM:efbUVIU2X9k:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/9GfFtYak0eM" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FLyzxErk1D0" height="1" width="1" alt=""/&gt;</content><summary>For some time now we've been working on updating your experience using Code Ready Containers, a container platform installation for your local machine, by providing interesting developer tooling and project examples. There is no better way to learn about container technologies, container platforms, and container-based application development than getting hands-on with great open technologies. This...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-01-09T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/9GfFtYak0eM/code-ready-containers-process-automation-developer-tools-update.html</feedburner:origLink></entry></feed>
